<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-23T08:49:09+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "sv"
}
-->
# AI-agenter i produktion: Observabilitet och utv√§rdering

N√§r AI-agenter g√•r fr√•n experimentella prototyper till verkliga applikationer blir det viktigt att f√∂rst√• deras beteende, √∂vervaka deras prestanda och systematiskt utv√§rdera deras resultat.

## L√§randem√•l

Efter att ha genomf√∂rt denna lektion kommer du att veta hur man/ha f√∂rst√•else f√∂r:
- Grundl√§ggande koncept kring observabilitet och utv√§rdering av agenter
- Tekniker f√∂r att f√∂rb√§ttra agenters prestanda, kostnader och effektivitet
- Vad och hur du systematiskt utv√§rderar dina AI-agenter
- Hur du kontrollerar kostnader vid implementering av AI-agenter i produktion
- Hur du instrumenterar agenter byggda med AutoGen

M√•let √§r att ge dig kunskap f√∂r att omvandla dina "svarta l√•dor" till transparenta, hanterbara och p√•litliga system.

_**Obs:** Det √§r viktigt att implementera AI-agenter som √§r s√§kra och p√•litliga. Kolla in lektionen [Bygga p√•litliga AI-agenter](./06-building-trustworthy-agents/README.md) ocks√•._

## Traces och Spans

Observabilitetsverktyg som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerar vanligtvis agentk√∂rningar som traces och spans.

- **Trace** representerar en komplett agentuppgift fr√•n b√∂rjan till slut (som att hantera en anv√§ndarfr√•ga).
- **Spans** √§r individuella steg inom trace (som att anropa en spr√•kmodell eller h√§mta data).

![Trace-tr√§d i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Utan observabilitet kan en AI-agent k√§nnas som en "svart l√•da" ‚Äì dess interna tillst√•nd och resonemang √§r otydliga, vilket g√∂r det sv√•rt att diagnostisera problem eller optimera prestanda. Med observabilitet blir agenter "glasl√•dor" och erbjuder den transparens som √§r avg√∂rande f√∂r att bygga f√∂rtroende och s√§kerst√§lla att de fungerar som avsett.

## Varf√∂r observabilitet √§r viktigt i produktionsmilj√∂er

Att √∂verf√∂ra AI-agenter till produktionsmilj√∂er medf√∂r nya utmaningar och krav. Observabilitet √§r inte l√§ngre en "trevlig att ha"-funktion utan en kritisk f√∂rm√•ga:

*   **Fels√∂kning och rotorsaksanalys**: N√§r en agent misslyckas eller ger ett ov√§ntat resultat, tillhandah√•ller observabilitetsverktyg de traces som beh√∂vs f√∂r att identifiera k√§llan till felet. Detta √§r s√§rskilt viktigt i komplexa agenter som kan involvera flera LLM-anrop, verktygsinteraktioner och villkorlig logik.
*   **Latens- och kostnadshantering**: AI-agenter f√∂rlitar sig ofta p√• LLM:er och andra externa API:er som debiteras per token eller per anrop. Observabilitet m√∂jligg√∂r exakt sp√•rning av dessa anrop, vilket hj√§lper till att identifiera operationer som √§r on√∂digt l√•ngsamma eller dyra. Detta g√∂r det m√∂jligt f√∂r team att optimera prompts, v√§lja mer effektiva modeller eller omdesigna arbetsfl√∂den f√∂r att hantera driftskostnader och s√§kerst√§lla en bra anv√§ndarupplevelse.
*   **F√∂rtroende, s√§kerhet och efterlevnad**: I m√•nga applikationer √§r det viktigt att s√§kerst√§lla att agenter beter sig s√§kert och etiskt. Observabilitet tillhandah√•ller en granskningssp√•r av agentens handlingar och beslut. Detta kan anv√§ndas f√∂r att uppt√§cka och √•tg√§rda problem som promptinjektion, generering av skadligt inneh√•ll eller felaktig hantering av personligt identifierbar information (PII). Till exempel kan du granska traces f√∂r att f√∂rst√• varf√∂r en agent gav ett visst svar eller anv√§nde ett specifikt verktyg.
*   **Kontinuerliga f√∂rb√§ttringsloopar**: Observabilitetsdata √§r grunden f√∂r en iterativ utvecklingsprocess. Genom att √∂vervaka hur agenter presterar i verkligheten kan team identifiera f√∂rb√§ttringsomr√•den, samla in data f√∂r att finjustera modeller och validera effekten av f√∂r√§ndringar. Detta skapar en feedbackloop d√§r produktionsinsikter fr√•n onlineutv√§rdering informerar offlineexperiment och f√∂rfining, vilket leder till successivt b√§ttre agentprestanda.

## Viktiga m√§tv√§rden att sp√•ra

F√∂r att √∂vervaka och f√∂rst√• agentbeteende b√∂r en rad m√§tv√§rden och signaler sp√•ras. √Ñven om de specifika m√§tv√§rdena kan variera beroende p√• agentens syfte, √§r vissa universellt viktiga.

H√§r √§r n√•gra av de vanligaste m√§tv√§rdena som observabilitetsverktyg √∂vervakar:

**Latens:** Hur snabbt svarar agenten? L√•nga v√§ntetider p√•verkar anv√§ndarupplevelsen negativt. Du b√∂r m√§ta latens f√∂r uppgifter och individuella steg genom att sp√•ra agentk√∂rningar. Till exempel kan en agent som tar 20 sekunder f√∂r alla modellanrop accelereras genom att anv√§nda en snabbare modell eller genom att k√∂ra modellanrop parallellt.

**Kostnader:** Vad √§r kostnaden per agentk√∂rning? AI-agenter f√∂rlitar sig p√• LLM-anrop som debiteras per token eller externa API:er. Frekvent verktygsanv√§ndning eller flera prompts kan snabbt √∂ka kostnaderna. Till exempel, om en agent anropar en LLM fem g√•nger f√∂r marginell kvalitetsf√∂rb√§ttring, m√•ste du bed√∂ma om kostnaden √§r motiverad eller om du kan minska antalet anrop eller anv√§nda en billigare modell. Realtids√∂vervakning kan ocks√• hj√§lpa till att identifiera ov√§ntade toppar (t.ex. buggar som orsakar √∂verdrivna API-loopar).

**Beg√§ransfel:** Hur m√•nga beg√§randen misslyckades agenten med? Detta kan inkludera API-fel eller misslyckade verktygsanrop. F√∂r att g√∂ra din agent mer robust mot dessa i produktion kan du sedan st√§lla in fallback-alternativ eller omf√∂rs√∂k. T.ex. om LLM-leverant√∂r A √§r nere, byter du till LLM-leverant√∂r B som backup.

**Anv√§ndarfeedback:** Implementering av direkt anv√§ndarutv√§rdering ger v√§rdefulla insikter. Detta kan inkludera explicita betyg (üëçtumme upp/üëéner, ‚≠ê1-5 stj√§rnor) eller textkommentarer. Konsekvent negativ feedback b√∂r varna dig eftersom det √§r ett tecken p√• att agenten inte fungerar som f√∂rv√§ntat.

**Implicit anv√§ndarfeedback:** Anv√§ndarbeteenden ger indirekt feedback √§ven utan explicita betyg. Detta kan inkludera omedelbar omformulering av fr√•gor, upprepade fr√•gor eller att klicka p√• en omf√∂rs√∂ksknapp. T.ex. om du ser att anv√§ndare upprepade g√•nger st√§ller samma fr√•ga √§r det ett tecken p√• att agenten inte fungerar som f√∂rv√§ntat.

**Noggrannhet:** Hur ofta producerar agenten korrekta eller √∂nskv√§rda resultat? Definitioner av noggrannhet varierar (t.ex. korrekthet i probleml√∂sning, noggrannhet vid informationsh√§mtning, anv√§ndarn√∂jdhet). Det f√∂rsta steget √§r att definiera vad framg√•ng inneb√§r f√∂r din agent. Du kan sp√•ra noggrannhet via automatiska kontroller, utv√§rderingspo√§ng eller etiketter f√∂r uppgiftskomplettering. Till exempel, markera traces som "lyckades" eller "misslyckades".

**Automatiserade utv√§rderingsm√§tv√§rden:** Du kan ocks√• st√§lla in automatiserade utv√§rderingar. Till exempel kan du anv√§nda en LLM f√∂r att betygs√§tta agentens output, t.ex. om den √§r hj√§lpsam, korrekt eller inte. Det finns ocks√• flera open source-bibliotek som hj√§lper dig att betygs√§tta olika aspekter av agenten. T.ex. [RAGAS](https://docs.ragas.io/) f√∂r RAG-agenter eller [LLM Guard](https://llm-guard.com/) f√∂r att uppt√§cka skadligt spr√•k eller promptinjektion.

I praktiken ger en kombination av dessa m√§tv√§rden den b√§sta t√§ckningen av en AI-agents h√§lsa. I detta kapitels [exempeldokument](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) visar vi hur dessa m√§tv√§rden ser ut i verkliga exempel, men f√∂rst ska vi l√§ra oss hur ett typiskt utv√§rderingsarbetsfl√∂de ser ut.

## Instrumentera din agent

F√∂r att samla in tracing-data m√•ste du instrumentera din kod. M√•let √§r att instrumentera agentkoden f√∂r att generera traces och m√§tv√§rden som kan f√•ngas, bearbetas och visualiseras av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har blivit en industristandard f√∂r observabilitet av LLM. Det tillhandah√•ller en upps√§ttning API:er, SDK:er och verktyg f√∂r att generera, samla in och exportera telemetridata.

Det finns m√•nga instrumenteringsbibliotek som omsluter befintliga agentramverk och g√∂r det enkelt att exportera OpenTelemetry-spans till ett observabilitetsverktyg. Nedan √§r ett exempel p√• hur man instrumenterar en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Exempeldokumentet](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) i detta kapitel kommer att demonstrera hur du instrumenterar din AutoGen-agent.

**Manuell skapande av spans:** √Ñven om instrumenteringsbibliotek tillhandah√•ller en bra grund, finns det ofta fall d√§r mer detaljerad eller anpassad information beh√∂vs. Du kan manuellt skapa spans f√∂r att l√§gga till anpassad applikationslogik. √Ñnnu viktigare √§r att de kan berika automatiskt eller manuellt skapade spans med anpassade attribut (√§ven k√§nda som taggar eller metadata). Dessa attribut kan inkludera aff√§rsspecifik data, mellanliggande ber√§kningar eller n√•gon kontext som kan vara anv√§ndbar f√∂r fels√∂kning eller analys, s√•som `user_id`, `session_id` eller `model_version`.

Exempel p√• att skapa traces och spans manuellt med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Utv√§rdering av agenter

Observabilitet ger oss m√§tv√§rden, men utv√§rdering √§r processen att analysera dessa data (och utf√∂ra tester) f√∂r att avg√∂ra hur v√§l en AI-agent presterar och hur den kan f√∂rb√§ttras. Med andra ord, n√§r du har dessa traces och m√§tv√§rden, hur anv√§nder du dem f√∂r att bed√∂ma agenten och fatta beslut?

Regelbunden utv√§rdering √§r viktig eftersom AI-agenter ofta √§r icke-deterministiska och kan utvecklas (genom uppdateringar eller f√∂r√§ndrat modellbeteende) ‚Äì utan utv√§rdering skulle du inte veta om din "smarta agent" faktiskt g√∂r sitt jobb bra eller om den har f√∂rs√§mrats.

Det finns tv√• kategorier av utv√§rderingar f√∂r AI-agenter: **onlineutv√§rdering** och **offlineutv√§rdering**. B√•da √§r v√§rdefulla och kompletterar varandra. Vi b√∂rjar vanligtvis med offlineutv√§rdering, eftersom detta √§r det minsta n√∂dv√§ndiga steget innan n√•gon agent implementeras.

### Offlineutv√§rdering

![Datasetobjekt i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Detta inneb√§r att utv√§rdera agenten i en kontrollerad milj√∂, vanligtvis med testdatam√§ngder, inte live-anv√§ndarfr√•gor. Du anv√§nder kuraterade datam√§ngder d√§r du vet vad det f√∂rv√§ntade resultatet eller korrekta beteendet √§r och k√∂r sedan din agent p√• dessa.

Till exempel, om du byggde en agent f√∂r matematiska ordproblem, kan du ha en [testdatam√§ngd](https://huggingface.co/datasets/gsm8k) med 100 problem med k√§nda svar. Offlineutv√§rdering g√∂rs ofta under utveckling (och kan vara en del av CI/CD-pipelines) f√∂r att kontrollera f√∂rb√§ttringar eller skydda mot f√∂rs√§mringar. F√∂rdelen √§r att det √§r **upprepbart och du kan f√• tydliga noggrannhetsm√§tv√§rden eftersom du har facit**. Du kan ocks√• simulera anv√§ndarfr√•gor och m√§ta agentens svar mot ideala svar eller anv√§nda automatiserade m√§tv√§rden som beskrivs ovan.

Den st√∂rsta utmaningen med offlineutv√§rdering √§r att s√§kerst√§lla att din testdatam√§ngd √§r omfattande och f√∂rblir relevant ‚Äì agenten kan prestera bra p√• en fast testm√§ngd men st√∂ta p√• helt andra fr√•gor i produktion. D√§rf√∂r b√∂r du h√•lla testm√§ngder uppdaterade med nya edge cases och exempel som speglar verkliga scenarier‚Äã. En blandning av sm√• "r√∂ktest"-fall och st√∂rre utv√§rderingsm√§ngder √§r anv√§ndbar: sm√• m√§ngder f√∂r snabba kontroller och st√∂rre f√∂r bredare prestandam√§tningar‚Äã.

### Onlineutv√§rdering

![√ñversikt √∂ver observabilitetsm√§tv√§rden](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Detta avser att utv√§rdera agenten i en live, verklig milj√∂, dvs. under faktisk anv√§ndning i produktion. Onlineutv√§rdering inneb√§r att kontinuerligt √∂vervaka agentens prestanda p√• verkliga anv√§ndarinteraktioner och analysera resultat.

Till exempel kan du sp√•ra framg√•ngsfrekvenser, anv√§ndarn√∂jdhetspo√§ng eller andra m√§tv√§rden p√• live-trafik. F√∂rdelen med onlineutv√§rdering √§r att det **f√•ngar saker du kanske inte f√∂rutser i en labbmilj√∂** ‚Äì du kan observera modellf√∂r√§ndringar √∂ver tid (om agentens effektivitet f√∂rs√§mras n√§r inmatningsm√∂nster f√∂r√§ndras) och f√•nga ov√§ntade fr√•gor eller situationer som inte fanns i dina testdata‚Äã. Det ger en sann bild av hur agenten beter sig i verkligheten.

Onlineutv√§rdering inneb√§r ofta att samla in implicit och explicit anv√§ndarfeedback, som diskuterats, och eventuellt k√∂ra skuggtester eller A/B-tester (d√§r en ny version av agenten k√∂rs parallellt f√∂r att j√§mf√∂ras med den gamla). Utmaningen √§r att det kan vara sv√•rt att f√• tillf√∂rlitliga etiketter eller po√§ng f√∂r live-interaktioner ‚Äì du kan beh√∂va f√∂rlita dig p√• anv√§ndarfeedback eller nedstr√∂msm√§tv√§rden (som om anv√§ndaren klickade p√• resultatet).

### Kombinera de tv√•

Online- och offlineutv√§rderingar utesluter inte varandra; de kompletterar varandra starkt. Insikter fr√•n online√∂vervakning (t.ex. nya typer av anv√§ndarfr√•gor d√§r agenten presterar d√•ligt) kan anv√§ndas f√∂r att ut√∂ka och f√∂rb√§ttra offline-testdatam√§ngder. Omv√§nt kan agenter som presterar bra i offline-tester sedan implementeras och √∂vervakas online med st√∂rre sj√§lvf√∂rtroende.

Faktum √§r att m√•nga team antar en loop:

_utv√§rdera offline -> implementera -> √∂vervaka online -> samla in nya felaktiga fall -> l√§gg till i offline-dataset -> f√∂rfina agent -> upprepa_.

## Vanliga problem

N√§r du implementerar AI-agenter i produktion kan du st√∂ta p√• olika utmaningar. H√§r √§r n√•gra vanliga problem och deras m√∂jliga l√∂sningar:

| **Problem**    | **M√∂jlig l√∂sning**   |
| ------------- | ------------------ |
| AI-agenten utf√∂r inte uppgifter konsekvent | - F√∂rfina prompten som ges till AI-agenten; var tydlig med m√•len.<br>- Identifiera om det kan hj√§lpa att dela upp uppgifterna i deluppgifter och hantera dem med flera agenter. |
| AI-agenten fastnar i kontinuerliga loopar  | - S√§kerst√§ll att du har tydliga avslutningsvillkor s√• att agenten vet n√§r processen ska avslutas.<br>- F√∂r komplexa uppgifter som kr√§ver resonemang och planering, anv√§nd en st√∂rre modell som √§r specialiserad f√∂r resonemangsuppgifter. |
| AI-agentens verktygsanrop fungerar inte bra   | - Testa och validera verktygets output utanf√∂r agentsystemet.

- F√∂rfina de definierade parametrarna, uppmaningarna och namngivningen av verktyg.  |
| Multi-Agent-systemet presterar inte konsekvent | - F√∂rfina uppmaningarna som ges till varje agent f√∂r att s√§kerst√§lla att de √§r specifika och skiljer sig fr√•n varandra.<br>- Bygg ett hierarkiskt system med en "routing"- eller kontrollagent f√∂r att avg√∂ra vilken agent som √§r den r√§tta. |

M√•nga av dessa problem kan identifieras mer effektivt med observabilitet p√• plats. De sp√•r och m√§tv√§rden vi diskuterade tidigare hj√§lper till att exakt lokalisera var i agentens arbetsfl√∂de problemen uppst√•r, vilket g√∂r fels√∂kning och optimering mycket mer effektivt.

## Hantering av kostnader

H√§r √§r n√•gra strategier f√∂r att hantera kostnaderna f√∂r att implementera AI-agenter i produktion:

**Anv√§nda mindre modeller:** Sm√• spr√•kmodeller (SLM) kan fungera bra f√∂r vissa agentbaserade anv√§ndningsfall och kommer att minska kostnaderna avsev√§rt. Som n√§mnts tidigare √§r det b√§sta s√§ttet att f√∂rst√• hur v√§l en SLM kommer att prestera f√∂r ditt anv√§ndningsfall att bygga ett utv√§rderingssystem f√∂r att avg√∂ra och j√§mf√∂ra prestanda mot st√∂rre modeller. √ñverv√§g att anv√§nda SLM f√∂r enklare uppgifter som avsiktsklassificering eller parameterutvinning, och reservera st√∂rre modeller f√∂r komplexa resonemangsuppgifter.

**Anv√§nda en routermodell:** En liknande strategi √§r att anv√§nda en m√•ngfald av modeller och storlekar. Du kan anv√§nda en LLM/SLM eller serverl√∂s funktion f√∂r att dirigera f√∂rfr√•gningar baserat p√• komplexitet till de mest l√§mpliga modellerna. Detta kommer ocks√• att hj√§lpa till att minska kostnaderna samtidigt som prestandan s√§kerst√§lls f√∂r r√§tt uppgifter. Till exempel, dirigera enkla fr√•gor till mindre, snabbare modeller och anv√§nd endast dyra stora modeller f√∂r komplexa resonemangsuppgifter.

**Cacha svar:** Identifiera vanliga f√∂rfr√•gningar och uppgifter och tillhandah√•ll svaren innan de g√•r igenom ditt agentbaserade system. Du kan till och med implementera ett fl√∂de f√∂r att identifiera hur lik en f√∂rfr√•gan √§r dina cachade f√∂rfr√•gningar med hj√§lp av enklare AI-modeller. Denna strategi kan avsev√§rt minska kostnaderna f√∂r vanliga fr√•gor eller √•terkommande arbetsfl√∂den.

## L√•t oss se hur detta fungerar i praktiken

I [exempeldagboken f√∂r detta avsnitt](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) kommer vi att se exempel p√• hur vi kan anv√§nda observabilitetsverktyg f√∂r att √∂vervaka och utv√§rdera v√•r agent.

## F√∂reg√•ende lektion

[Metakognitionsdesignm√∂nster](../09-metacognition/README.md)

## N√§sta lektion

[MCP](../11-mcp/README.md)

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiska √∂vers√§ttningar kan inneh√•lla fel eller inexaktheter. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.