<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a9631d0898fc3c6ecbb3a8a0da7aaba3",
  "translation_date": "2025-08-30T14:28:38+00:00",
  "source_file": "02-explore-agentic-frameworks/README.md",
  "language_code": "pl"
}
-->
[![Eksploracja Framework贸w Agent贸w AI](../../../translated_images/lesson-2-thumbnail.c65f44c93b8558df4d5d407e29970e654629e614f357444a9c27c80feb54c79d.pl.png)](https://youtu.be/ODwF-EZo_O8?si=1xoy_B9RNQfrYdF7)

> _(Kliknij obrazek powy偶ej, aby obejrze wideo do tej lekcji)_

# Eksploracja Framework贸w Agent贸w AI

Frameworki agent贸w AI to platformy programistyczne zaprojektowane, aby uproci tworzenie, wdra偶anie i zarzdzanie agentami AI. Dostarczaj one programistom gotowe komponenty, abstrakcje i narzdzia, kt贸re usprawniaj rozw贸j zo偶onych system贸w AI.

Frameworki te pozwalaj programistom skupi si na unikalnych aspektach ich aplikacji, oferujc ustandaryzowane podejcia do typowych wyzwa w rozwoju agent贸w AI. Zwikszaj skalowalno, dostpno i efektywno w budowaniu system贸w AI.

## Wprowadzenie

W tej lekcji om贸wimy:

- Czym s frameworki agent贸w AI i co umo偶liwiaj programistom osign?
- Jak zespoy mog je wykorzysta do szybkiego prototypowania, iteracji i ulepszania mo偶liwoci swoich agent贸w?
- Jakie s r贸偶nice midzy frameworkami i narzdziami stworzonymi przez Microsoft, a innymi rozwizaniami?
- Czy mog zintegrowa istniejce narzdzia ekosystemu Azure bezporednio, czy potrzebuj samodzielnych rozwiza?
- Czym jest usuga Azure AI Agents i jak mo偶e mi pom贸c?

## Cele nauki

Celem tej lekcji jest zrozumienie:

- Roli framework贸w agent贸w AI w rozwoju AI.
- Jak wykorzysta frameworki agent贸w AI do budowy inteligentnych agent贸w.
- Kluczowych mo偶liwoci oferowanych przez frameworki agent贸w AI.
- R贸偶nic midzy AutoGen, Semantic Kernel i Azure AI Agent Service.

## Czym s frameworki agent贸w AI i co umo偶liwiaj programistom?

Tradycyjne frameworki AI mog pom贸c w integracji AI z aplikacjami i poprawi ich dziaanie w nastpujcy spos贸b:

- **Personalizacja**: AI mo偶e analizowa zachowanie u偶ytkownik贸w i ich preferencje, aby dostarcza spersonalizowane rekomendacje, treci i dowiadczenia.  
Przykad: Serwisy streamingowe, takie jak Netflix, wykorzystuj AI do sugerowania film贸w i seriali na podstawie historii ogldania, zwikszajc zaanga偶owanie i satysfakcj u偶ytkownik贸w.
- **Automatyzacja i efektywno**: AI mo偶e automatyzowa powtarzalne zadania, usprawnia przepywy pracy i poprawia efektywno operacyjn.  
Przykad: Aplikacje obsugi klienta wykorzystuj chatboty oparte na AI do obsugi typowych zapyta, skracajc czas odpowiedzi i odci偶ajc ludzkich agent贸w w bardziej zo偶onych sprawach.
- **Poprawa dowiadczenia u偶ytkownika**: AI mo偶e poprawi og贸lne dowiadczenie u偶ytkownika, oferujc inteligentne funkcje, takie jak rozpoznawanie gosu, przetwarzanie jzyka naturalnego i przewidywanie tekstu.  
Przykad: Wirtualni asystenci, tacy jak Siri i Google Assistant, wykorzystuj AI do rozumienia i odpowiadania na polecenia gosowe, uatwiajc u偶ytkownikom interakcj z urzdzeniami.

### Brzmi wietnie, prawda? Wic dlaczego potrzebujemy framework贸w agent贸w AI?

Frameworki agent贸w AI to co wicej ni偶 tylko frameworki AI. S one zaprojektowane, aby umo偶liwi tworzenie inteligentnych agent贸w, kt贸rzy mog wchodzi w interakcje z u偶ytkownikami, innymi agentami i rodowiskiem, aby osiga okrelone cele. Agenci ci mog wykazywa autonomiczne zachowanie, podejmowa decyzje i dostosowywa si do zmieniajcych si warunk贸w. Oto kluczowe mo偶liwoci oferowane przez frameworki agent贸w AI:

- **Wsp贸praca i koordynacja agent贸w**: Umo偶liwiaj tworzenie wielu agent贸w AI, kt贸rzy mog wsp贸pracowa, komunikowa si i koordynowa dziaania w celu rozwizania zo偶onych zada.
- **Automatyzacja i zarzdzanie zadaniami**: Zapewniaj mechanizmy automatyzacji wieloetapowych przepyw贸w pracy, delegowania zada i dynamicznego zarzdzania zadaniami midzy agentami.
- **Zrozumienie kontekstu i adaptacja**: Wyposa偶aj agent贸w w zdolno rozumienia kontekstu, dostosowywania si do zmieniajcego si rodowiska i podejmowania decyzji na podstawie informacji w czasie rzeczywistym.

Podsumowujc, agenci pozwalaj robi wicej, przenosi automatyzacj na wy偶szy poziom, tworzy bardziej inteligentne systemy, kt贸re mog si uczy i dostosowywa do swojego rodowiska.

## Jak szybko prototypowa, iterowa i ulepsza mo偶liwoci agenta?

To dynamicznie rozwijajca si dziedzina, ale istniej pewne wsp贸lne elementy w wikszoci framework贸w agent贸w AI, kt贸re mog pom贸c w szybkim prototypowaniu i iteracji, takie jak moduowe komponenty, narzdzia do wsp贸pracy i uczenie si w czasie rzeczywistym. Przyjrzyjmy si im bli偶ej:

- **Wykorzystaj moduowe komponenty**: SDK AI oferuj gotowe komponenty, takie jak konektory AI i pamici, wywoywanie funkcji za pomoc jzyka naturalnego lub wtyczek kodu, szablony podpowiedzi i inne.
- **Wykorzystaj narzdzia do wsp贸pracy**: Projektuj agent贸w z okrelonymi rolami i zadaniami, umo偶liwiajc testowanie i udoskonalanie przepyw贸w wsp贸pracy.
- **Ucz si w czasie rzeczywistym**: Wdra偶aj ptle sprz偶enia zwrotnego, w kt贸rych agenci ucz si na podstawie interakcji i dynamicznie dostosowuj swoje zachowanie.

### Wykorzystaj moduowe komponenty

SDK, takie jak Microsoft Semantic Kernel i LangChain, oferuj gotowe komponenty, takie jak konektory AI, szablony podpowiedzi i zarzdzanie pamici.

**Jak zespoy mog to wykorzysta**: Zespoy mog szybko zo偶y te komponenty, aby stworzy funkcjonalny prototyp bez koniecznoci zaczynania od zera, co pozwala na szybkie eksperymentowanie i iteracj.

**Jak to dziaa w praktyce**: Mo偶esz u偶y gotowego parsera do wyodrbniania informacji z danych wejciowych u偶ytkownika, moduu pamici do przechowywania i pobierania danych oraz generatora podpowiedzi do interakcji z u偶ytkownikami, wszystko bez koniecznoci budowania tych komponent贸w od podstaw.

**Przykad kodu**. Przyjrzyjmy si przykadom u偶ycia gotowego konektora AI z Semantic Kernel w Pythonie i .Net, kt贸ry wykorzystuje automatyczne wywoywanie funkcji, aby model odpowiada na dane wejciowe u偶ytkownika:

``` python
# Semantic Kernel Python Example

import asyncio
from typing import Annotated

from semantic_kernel.connectors.ai import FunctionChoiceBehavior
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings
from semantic_kernel.contents import ChatHistory
from semantic_kernel.functions import kernel_function
from semantic_kernel.kernel import Kernel

# Define a ChatHistory object to hold the conversation's context
chat_history = ChatHistory()
chat_history.add_user_message("I'd like to go to New York on January 1, 2025")


# Define a sample plugin that contains the function to book travel
class BookTravelPlugin:
    """A Sample Book Travel Plugin"""

    @kernel_function(name="book_flight", description="Book travel given location and date")
    async def book_flight(
        self, date: Annotated[str, "The date of travel"], location: Annotated[str, "The location to travel to"]
    ) -> str:
        return f"Travel was booked to {location} on {date}"

# Create the Kernel
kernel = Kernel()

# Add the sample plugin to the Kernel object
kernel.add_plugin(BookTravelPlugin(), plugin_name="book_travel")

# Define the Azure OpenAI AI Connector
chat_service = AzureChatCompletion(
    deployment_name="YOUR_DEPLOYMENT_NAME", 
    api_key="YOUR_API_KEY", 
    endpoint="https://<your-resource>.azure.openai.com/",
)

# Define the request settings to configure the model with auto-function calling
request_settings = AzureChatPromptExecutionSettings(function_choice_behavior=FunctionChoiceBehavior.Auto())


async def main():
    # Make the request to the model for the given chat history and request settings
    # The Kernel contains the sample that the model will request to invoke
    response = await chat_service.get_chat_message_content(
        chat_history=chat_history, settings=request_settings, kernel=kernel
    )
    assert response is not None

    """
    Note: In the auto function calling process, the model determines it can invoke the 
    `BookTravelPlugin` using the `book_flight` function, supplying the necessary arguments. 
    
    For example:

    "tool_calls": [
        {
            "id": "call_abc123",
            "type": "function",
            "function": {
                "name": "BookTravelPlugin-book_flight",
                "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
            }
        }
    ]

    Since the location and date arguments are required (as defined by the kernel function), if the 
    model lacks either, it will prompt the user to provide them. For instance:

    User: Book me a flight to New York.
    Model: Sure, I'd love to help you book a flight. Could you please specify the date?
    User: I want to travel on January 1, 2025.
    Model: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels!
    """

    print(f"`{response}`")
    # Example AI Model Response: `Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! 锔`

    # Add the model's response to our chat history context
    chat_history.add_assistant_message(response.content)


if __name__ == "__main__":
    asyncio.run(main())
```  
```csharp
// Semantic Kernel C# example

using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using System.ComponentModel;
using Microsoft.SemanticKernel.Connectors.AzureOpenAI;

ChatHistory chatHistory = [];
chatHistory.AddUserMessage("I'd like to go to New York on January 1, 2025");

var kernelBuilder = Kernel.CreateBuilder();
kernelBuilder.AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT"
);
kernelBuilder.Plugins.AddFromType<BookTravelPlugin>("BookTravel"); 
var kernel = kernelBuilder.Build();

var settings = new AzureOpenAIPromptExecutionSettings()
{
    FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
};

var chatCompletion = kernel.GetRequiredService<IChatCompletionService>();

var response = await chatCompletion.GetChatMessageContentAsync(chatHistory, settings, kernel);

/*
Behind the scenes, the model recognizes the tool to call, what arguments it already has (location) and (date)
{

"tool_calls": [
    {
        "id": "call_abc123",
        "type": "function",
        "function": {
            "name": "BookTravelPlugin-book_flight",
            "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
        }
    }
]
*/

Console.WriteLine(response.Content);
chatHistory.AddMessage(response!.Role, response!.Content!);

// Example AI Model Response: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! 锔

// Define a plugin that contains the function to book travel
public class BookTravelPlugin
{
    [KernelFunction("book_flight")]
    [Description("Book travel given location and date")]
    public async Task<string> BookFlight(DateTime date, string location)
    {
        return await Task.FromResult( $"Travel was booked to {location} on {date}");
    }
}
```  

W tym przykadzie wida, jak mo偶na wykorzysta gotowy parser do wyodrbniania kluczowych informacji z danych wejciowych u偶ytkownika, takich jak miejsce pocztkowe, miejsce docelowe i data rezerwacji lotu. Takie moduowe podejcie pozwala skupi si na logice wysokiego poziomu.

### Wykorzystaj narzdzia do wsp贸pracy

Frameworki, takie jak CrewAI, Microsoft AutoGen i Semantic Kernel, uatwiaj tworzenie wielu agent贸w, kt贸rzy mog wsp贸pracowa.

**Jak zespoy mog to wykorzysta**: Zespoy mog projektowa agent贸w z okrelonymi rolami i zadaniami, umo偶liwiajc testowanie i udoskonalanie przepyw贸w wsp贸pracy oraz popraw og贸lnej efektywnoci systemu.

**Jak to dziaa w praktyce**: Mo偶esz stworzy zesp贸 agent贸w, gdzie ka偶dy agent ma wyspecjalizowan funkcj, tak jak pobieranie danych, analiza lub podejmowanie decyzji. Agenci ci mog komunikowa si i wymienia informacje, aby osign wsp贸lny cel, na przykad odpowiedzie na zapytanie u偶ytkownika lub wykona zadanie.

**Przykad kodu (AutoGen)**:

```python
# creating agents, then create a round robin schedule where they can work together, in this case in order

# Data Retrieval Agent
# Data Analysis Agent
# Decision Making Agent

agent_retrieve = AssistantAgent(
    name="dataretrieval",
    model_client=model_client,
    tools=[retrieve_tool],
    system_message="Use tools to solve tasks."
)

agent_analyze = AssistantAgent(
    name="dataanalysis",
    model_client=model_client,
    tools=[analyze_tool],
    system_message="Use tools to solve tasks."
)

# conversation ends when user says "APPROVE"
termination = TextMentionTermination("APPROVE")

user_proxy = UserProxyAgent("user_proxy", input_func=input)

team = RoundRobinGroupChat([agent_retrieve, agent_analyze, user_proxy], termination_condition=termination)

stream = team.run_stream(task="Analyze data", max_turns=10)
# Use asyncio.run(...) when running in a script.
await Console(stream)
```  

W poprzednim kodzie wida, jak mo偶na stworzy zadanie, kt贸re obejmuje wsp贸prac wielu agent贸w analizujcych dane. Ka偶dy agent wykonuje okrelon funkcj, a zadanie jest realizowane poprzez koordynacj dziaa agent贸w w celu osignicia po偶danego wyniku. Tworzc dedykowanych agent贸w z wyspecjalizowanymi rolami, mo偶na poprawi efektywno i wydajno zada.

### Ucz si w czasie rzeczywistym

Zaawansowane frameworki oferuj mo偶liwoci zrozumienia kontekstu i adaptacji w czasie rzeczywistym.

**Jak zespoy mog to wykorzysta**: Zespoy mog wdra偶a ptle sprz偶enia zwrotnego, w kt贸rych agenci ucz si na podstawie interakcji i dynamicznie dostosowuj swoje zachowanie, co prowadzi do cigego doskonalenia i udoskonalania mo偶liwoci.

**Jak to dziaa w praktyce**: Agenci mog analizowa opinie u偶ytkownik贸w, dane rodowiskowe i wyniki zada, aby aktualizowa swoj baz wiedzy, dostosowywa algorytmy podejmowania decyzji i poprawia wydajno w czasie. Ten iteracyjny proces uczenia si pozwala agentom dostosowywa si do zmieniajcych si warunk贸w i preferencji u偶ytkownik贸w, zwikszajc og贸ln skuteczno systemu.

## Jakie s r贸偶nice midzy frameworkami AutoGen, Semantic Kernel i Azure AI Agent Service?

Istnieje wiele sposob贸w por贸wnania tych framework贸w, ale przyjrzyjmy si kluczowym r贸偶nicom w zakresie ich projektowania, mo偶liwoci i docelowych przypadk贸w u偶ycia:

## AutoGen

AutoGen to framework open-source opracowany przez Microsoft Research's AI Frontiers Lab. Skupia si na aplikacjach agentowych opartych na zdarzeniach, rozproszonych, umo偶liwiajc wykorzystanie wielu LLM, SLM, narzdzi i zaawansowanych wzorc贸w projektowych dla wielu agent贸w.

AutoGen opiera si na podstawowej koncepcji agent贸w, czyli autonomicznych jednostek, kt贸re mog postrzega swoje rodowisko, podejmowa decyzje i podejmowa dziaania w celu osignicia okrelonych cel贸w. Agenci komunikuj si za pomoc asynchronicznych wiadomoci, co pozwala im dziaa niezale偶nie i r贸wnolegle, zwikszajc skalowalno i responsywno systemu.

Wedug Wikipedii, aktor to _podstawowy element oblicze wsp贸bie偶nych. W odpowiedzi na otrzyman wiadomo aktor mo偶e: podejmowa lokalne decyzje, tworzy wicej aktor贸w, wysya wicej wiadomoci i okrela, jak odpowiedzie na kolejn otrzyman wiadomo_.

**Przypadki u偶ycia**: Automatyzacja generowania kodu, zadania analizy danych, budowanie niestandardowych agent贸w do funkcji planowania i bada.

Oto kilka wa偶nych podstawowych koncepcji AutoGen:

- **Agenci**. Agent to jednostka programowa, kt贸ra:  
  - **Komunikuje si za pomoc wiadomoci**, kt贸re mog by synchroniczne lub asynchroniczne.  
  - **Utrzymuje wasny stan**, kt贸ry mo偶e by modyfikowany przez przychodzce wiadomoci.  
  - **Wykonuje dziaania** w odpowiedzi na otrzymane wiadomoci lub zmiany w swoim stanie. Dziaania te mog modyfikowa stan agenta i wywoywa efekty zewntrzne, takie jak aktualizacja dziennik贸w wiadomoci, wysyanie nowych wiadomoci, wykonywanie kodu lub wywoywanie API.  

  Oto kr贸tki fragment kodu, w kt贸rym tworzysz wasnego agenta z funkcjami czatu:

    ```python
    from autogen_agentchat.agents import AssistantAgent
    from autogen_agentchat.messages import TextMessage
    from autogen_ext.models.openai import OpenAIChatCompletionClient


    class MyAssistant(RoutedAgent):
        def __init__(self, name: str) -> None:
            super().__init__(name)
            model_client = OpenAIChatCompletionClient(model="gpt-4o")
            self._delegate = AssistantAgent(name, model_client=model_client)
    
        @message_handler
        async def handle_my_message_type(self, message: MyMessageType, ctx: MessageContext) -> None:
            print(f"{self.id.type} received message: {message.content}")
            response = await self._delegate.on_messages(
                [TextMessage(content=message.content, source="user")], ctx.cancellation_token
            )
            print(f"{self.id.type} responded: {response.chat_message.content}")
    ```  

    W powy偶szym kodzie utworzono `MyAssistant`, kt贸ry dziedziczy po `RoutedAgent`. Ma on obsug wiadomoci, kt贸ra drukuje tre wiadomoci, a nastpnie wysya odpowied藕 za pomoc delegata `AssistantAgent`. Szczeg贸lnie warto zwr贸ci uwag, jak przypisujemy do `self._delegate` instancj `AssistantAgent`, kt贸ry jest wstpnie zbudowanym agentem obsugujcym uzupenienia czatu.

    Nastpnie poinformujmy AutoGen o tym typie agenta i uruchommy program:

    ```python
    
    # main.py
    runtime = SingleThreadedAgentRuntime()
    await MyAgent.register(runtime, "my_agent", lambda: MyAgent())

    runtime.start()  # Start processing messages in the background.
    await runtime.send_message(MyMessageType("Hello, World!"), AgentId("my_agent", "default"))
    ```  

    W powy偶szym kodzie agenci s rejestrowani w rodowisku wykonawczym, a nastpnie wysyana jest wiadomo do agenta, co skutkuje nastpujcym wynikiem:

    ```text
    # Output from the console:
    my_agent received message: Hello, World!
    my_assistant received message: Hello, World!
    my_assistant responded: Hello! How can I assist you today?
    ```  

- **Wielu agent贸w**. AutoGen obsuguje tworzenie wielu agent贸w, kt贸rzy mog wsp贸pracowa w celu realizacji zo偶onych zada. Agenci mog komunikowa si, wymienia informacje i koordynowa swoje dziaania, aby efektywniej rozwizywa problemy. Aby stworzy system wieloagentowy, mo偶esz zdefiniowa r贸偶ne typy agent贸w z wyspecjalizowanymi funkcjami i rolami, takimi jak pobieranie danych, analiza, podejmowanie decyzji i interakcja z u偶ytkownikiem. Zobaczmy, jak wyglda taka kreacja:

    ```python
    editor_description = "Editor for planning and reviewing the content."

    # Example of declaring an Agent
    editor_agent_type = await EditorAgent.register(
    runtime,
    editor_topic_type,  # Using topic type as the agent type.
    lambda: EditorAgent(
        description=editor_description,
        group_chat_topic_type=group_chat_topic_type,
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        ),
    )

    # remaining declarations shortened for brevity

    # Group chat
    group_chat_manager_type = await GroupChatManager.register(
    runtime,
    "group_chat_manager",
    lambda: GroupChatManager(
        participant_topic_types=[writer_topic_type, illustrator_topic_type, editor_topic_type, user_topic_type],
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        participant_descriptions=[
            writer_description, 
            illustrator_description, 
            editor_description, 
            user_description
        ],
        ),
    )
    ```  

    W powy偶szym kodzie mamy `GroupChatManager`, kt贸ry jest rejestrowany w rodowisku wykonawczym. Ten mened偶er odpowiada za koordynacj interakcji midzy r贸偶nymi typami agent贸w, takimi jak pisarze, ilustratorzy, redaktorzy i u偶ytkownicy.

- **rodowisko wykonawcze agenta**. Framework zapewnia rodowisko wykonawcze, umo偶liwiajce komunikacj midzy agentami, zarzdzanie ich to偶samociami i cyklami 偶ycia oraz egzekwowanie granic bezpieczestwa i prywatnoci. Oznacza to, 偶e mo偶esz uruchamia swoich agent贸w w bezpiecznym i kontrolowanym rodowisku, zapewniajc, 偶e mog one wchodzi w interakcje w spos贸b bezpieczny i efektywny. Istniej dwa interesujce rodowiska wykonawcze:
  - **Samodzielne rodowisko wykonawcze**. Jest to dobre rozwizanie dla aplikacji jednoprocesowych, w kt贸rych wszyscy agenci s zaimplementowani w tym samym jzyku programowania i dziaaj w tym samym procesie. Oto ilustracja, jak to dziaa:  

    Stos aplikacji  

    *agenci komunikuj si za pomoc wiadomoci przez rodowisko wykonawcze, kt贸re zarzdza cyklem 偶ycia agent贸w*

  - **Rozproszone rodowisko wykonawcze agent贸w**, odpowiednie dla aplikacji wieloprocesowych, w kt贸rych agenci mog by zaimplementowani w r贸偶nych jzykach programowania i dziaa na r贸偶nych maszynach. Oto ilustracja, jak to dziaa:  

## Semantic Kernel + Framework Agent贸w

Semantic Kernel to gotowe do zastosowa w przedsibiorstwach SDK do orkiestracji AI. Skada si z konektor贸w AI i pamici oraz Frameworka Agent贸w.

Najpierw om贸wmy kilka podstawowych komponent贸w:

- **Konektory AI**: Interfejs do zewntrznych usug AI i 藕r贸de danych, dostpny zar贸wno w Pythonie, jak i C#.

  ```python
  # Semantic Kernel Python
  from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
  from semantic_kernel.kernel import Kernel

  kernel = Kernel()
  kernel.add_service(
    AzureChatCompletion(
        deployment_name="your-deployment-name",
        api_key="your-api-key",
        endpoint="your-endpoint",
    )
  )
  ```  

    ```csharp
    // Semantic Kernel C#
    using Microsoft.SemanticKernel;

    // Create kernel
    var builder = Kernel.CreateBuilder();
    
    // Add a chat completion service:
    builder.Services.AddAzureOpenAIChatCompletion(
        "your-resource-name",
        "your-endpoint",
        "your-resource-key",
        "deployment-model");
    var kernel = builder.Build();
    ```  

    Tutaj masz prosty przykad, jak mo偶na utworzy kernel i doda usug uzupeniania czatu. Semantic Kernel tworzy poczenie z zewntrzn usug AI, w tym przypadku Azure OpenAI Chat Completion.

- **Wtyczki**: Enkapsuluj funkcje, kt贸re aplikacja mo偶e wykorzysta. Istniej zar贸wno gotowe wtyczki, jak i te, kt贸re mo偶esz stworzy samodzielnie. Powizanym pojciem s "funkcje podpowiedzi". Zamiast dostarcza wskaz贸wki w jzyku naturalnym do wywoywania funkcji, transmitujesz pewne funkcje do modelu. Na podstawie bie偶cego kontekstu czatu model mo偶e wybra wywoanie jednej z tych funkcji, aby zrealizowa 偶danie lub zapytanie. Oto przykad:

  ```python
  from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion


  async def main():
      from semantic_kernel.functions import KernelFunctionFromPrompt
      from semantic_kernel.kernel import Kernel

      kernel = Kernel()
      kernel.add_service(AzureChatCompletion())

      user_input = input("User Input:> ")

      kernel_function = KernelFunctionFromPrompt(
          function_name="SummarizeText",
          prompt="""
          Summarize the provided unstructured text in a sentence that is easy to understand.
          Text to summarize: {{$user_input}}
          """,
      )

      response = await kernel_function.invoke(kernel=kernel, user_input=user_input)
      print(f"Model Response: {response}")

      """
      Sample Console Output:

      User Input:> I like dogs
      Model Response: The text expresses a preference for dogs.
      """


  if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
  ```  

    ```csharp
    var userInput = Console.ReadLine();

    // Define semantic function inline.
    string skPrompt = @"Summarize the provided unstructured text in a sentence that is easy to understand.
                        Text to summarize: {{$userInput}}";
    
    // create the function from the prompt
    KernelFunction summarizeFunc = kernel.CreateFunctionFromPrompt(
        promptTemplate: skPrompt,
        functionName: "SummarizeText"
    );

    //then import into the current kernel
    kernel.ImportPluginFromFunctions("SemanticFunctions", [summarizeFunc]);

    ```  

    Tutaj najpierw masz szablon podpowiedzi `skPrompt`, kt贸ry pozostawia miejsce na dane wejciowe u偶ytkownika, `$userInput`. Nastpnie tworzysz funkcj kernela `SummarizeText`, a potem importujesz j do kernela pod nazw wtyczki `SemanticFunctions`. Zwr贸 uwag na nazw funkcji, kt贸ra pomaga Semantic Kernel zrozumie, co funkcja robi i kiedy powinna by wywoywana.

- **Funkcja natywna**: Istniej r贸wnie偶 funkcje natywne, kt贸re framework mo偶e wywoywa bezporednio w celu wykonania zadania. Oto przykad takiej funkcji pobierajcej zawarto z pliku:

    ```csharp
    public class NativeFunctions {

        [SKFunction, Description("Retrieve content from local file")]
        public async Task<string> RetrieveLocalFile(string fileName, int maxSize = 5000)
        {
            string content = await File.ReadAllTextAsync(fileName);
            if (content.Length <= maxSize) return content;
            return content.Substring(0, maxSize);
        }
    }
    
    //Import native function
    string plugInName = "NativeFunction";
    string functionName = "RetrieveLocalFile";

   //To add the functions to a kernel use the following function
    kernel.ImportPluginFromType<NativeFunctions>();

    ```  

- **Pami**: Abstrahuje i upraszcza zarzdzanie kontekstem dla aplikacji AI. Idea pamici polega na tym, 偶e jest to co, co LLM powinien wiedzie. Mo偶esz przechowywa te informacje w magazynie wektorowym
## Azure AI Agent Service

Azure AI Agent Service to nowszy dodatek, wprowadzony na Microsoft Ignite 2024. Umo偶liwia rozw贸j i wdra偶anie agent贸w AI z bardziej elastycznymi modelami, takimi jak bezporednie wywoywanie otwarto藕r贸dowych LLM-贸w, takich jak Llama 3, Mistral i Cohere.

Azure AI Agent Service oferuje silniejsze mechanizmy bezpieczestwa dla przedsibiorstw oraz metody przechowywania danych, co czyni go odpowiednim dla zastosowa korporacyjnych.

Dziaa od razu po instalacji z frameworkami do orkiestracji wieloagentowej, takimi jak AutoGen i Semantic Kernel.

Usuga ta jest obecnie dostpna w Public Preview i obsuguje jzyki Python oraz C# do budowy agent贸w.

Korzystajc z Semantic Kernel Python, mo偶emy stworzy agenta Azure AI z wtyczk zdefiniowan przez u偶ytkownika:

```python
import asyncio
from typing import Annotated

from azure.identity.aio import DefaultAzureCredential

from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread
from semantic_kernel.contents import ChatMessageContent
from semantic_kernel.contents import AuthorRole
from semantic_kernel.functions import kernel_function


# Define a sample plugin for the sample
class MenuPlugin:
    """A sample Menu Plugin used for the concept sample."""

    @kernel_function(description="Provides a list of specials from the menu.")
    def get_specials(self) -> Annotated[str, "Returns the specials from the menu."]:
        return """
        Special Soup: Clam Chowder
        Special Salad: Cobb Salad
        Special Drink: Chai Tea
        """

    @kernel_function(description="Provides the price of the requested menu item.")
    def get_item_price(
        self, menu_item: Annotated[str, "The name of the menu item."]
    ) -> Annotated[str, "Returns the price of the menu item."]:
        return "$9.99"


async def main() -> None:
    ai_agent_settings = AzureAIAgentSettings.create()

    async with (
        DefaultAzureCredential() as creds,
        AzureAIAgent.create_client(
            credential=creds,
            conn_str=ai_agent_settings.project_connection_string.get_secret_value(),
        ) as client,
    ):
        # Create agent definition
        agent_definition = await client.agents.create_agent(
            model=ai_agent_settings.model_deployment_name,
            name="Host",
            instructions="Answer questions about the menu.",
        )

        # Create the AzureAI Agent using the defined client and agent definition
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
            plugins=[MenuPlugin()],
        )

        # Create a thread to hold the conversation
        # If no thread is provided, a new thread will be
        # created and returned with the initial response
        thread: AzureAIAgentThread | None = None

        user_inputs = [
            "Hello",
            "What is the special soup?",
            "How much does that cost?",
            "Thank you",
        ]

        try:
            for user_input in user_inputs:
                print(f"# User: '{user_input}'")
                # Invoke the agent for the specified thread
                response = await agent.get_response(
                    messages=user_input,
                    thread_id=thread,
                )
                print(f"# {response.name}: {response.content}")
                thread = response.thread
        finally:
            await thread.delete() if thread else None
            await client.agents.delete_agent(agent.id)


if __name__ == "__main__":
    asyncio.run(main())
```

### Kluczowe pojcia

Azure AI Agent Service opiera si na nastpujcych kluczowych pojciach:

- **Agent**. Azure AI Agent Service integruje si z Azure AI Foundry. W ramach AI Foundry, agent AI dziaa jako "inteligentna" mikrousuga, kt贸ra mo偶e odpowiada na pytania (RAG), wykonywa dziaania lub cakowicie automatyzowa przepywy pracy. Osiga to, czc moc generatywnych modeli AI z narzdziami, kt贸re pozwalaj na dostp i interakcj z rzeczywistymi 藕r贸dami danych. Oto przykad agenta:

    ```python
    agent = project_client.agents.create_agent(
        model="gpt-4o-mini",
        name="my-agent",
        instructions="You are helpful agent",
        tools=code_interpreter.definitions,
        tool_resources=code_interpreter.resources,
    )
    ```

    W tym przykadzie agent zosta stworzony z modelem `gpt-4o-mini`, nazw `my-agent` i instrukcjami `You are helpful agent`. Agent jest wyposa偶ony w narzdzia i zasoby do wykonywania zada zwizanych z interpretacj kodu.

- **Wtek i wiadomoci**. Wtek to kolejne wa偶ne pojcie. Reprezentuje rozmow lub interakcj midzy agentem a u偶ytkownikiem. Wtki mog by u偶ywane do ledzenia postpu rozmowy, przechowywania informacji o kontekcie i zarzdzania stanem interakcji. Oto przykad wtku:

    ```python
    thread = project_client.agents.create_thread()
    message = project_client.agents.create_message(
        thread_id=thread.id,
        role="user",
        content="Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million",
    )
    
    # Ask the agent to perform work on the thread
    run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)
    
    # Fetch and log all messages to see the agent's response
    messages = project_client.agents.list_messages(thread_id=thread.id)
    print(f"Messages: {messages}")
    ```

    W powy偶szym kodzie utworzono wtek. Nastpnie do wtku wysano wiadomo. Wywoujc `create_and_process_run`, poproszono agenta o wykonanie pracy na wtku. Na kocu wiadomoci s pobierane i rejestrowane, aby zobaczy odpowied藕 agenta. Wiadomoci wskazuj postp rozmowy midzy u偶ytkownikiem a agentem. Wa偶ne jest r贸wnie偶 zrozumienie, 偶e wiadomoci mog mie r贸偶ne typy, takie jak tekst, obraz lub plik, co oznacza, 偶e praca agenta moga skutkowa np. obrazem lub odpowiedzi tekstow. Jako programista mo偶esz nastpnie wykorzysta te informacje do dalszego przetwarzania odpowiedzi lub przedstawienia jej u偶ytkownikowi.

- **Integracja z innymi frameworkami AI**. Usuga Azure AI Agent mo偶e wsp贸pracowa z innymi frameworkami, takimi jak AutoGen i Semantic Kernel, co oznacza, 偶e mo偶esz zbudowa cz swojej aplikacji w jednym z tych framework贸w, a na przykad u偶y usugi Agent jako orkiestratora lub zbudowa wszystko w usudze Agent.

**Zastosowania**: Azure AI Agent Service jest przeznaczona dla aplikacji korporacyjnych, kt贸re wymagaj bezpiecznego, skalowalnego i elastycznego wdra偶ania agent贸w AI.

## Czym r贸偶ni si te frameworki?

Mo偶e si wydawa, 偶e te frameworki maj wiele wsp贸lnego, ale istniej kluczowe r贸偶nice w ich projektowaniu, mo偶liwociach i docelowych zastosowaniach:

- **AutoGen**: To framework eksperymentalny, skoncentrowany na najnowszych badaniach nad systemami wieloagentowymi. Jest najlepszym miejscem do eksperymentowania i prototypowania zaawansowanych system贸w wieloagentowych.
- **Semantic Kernel**: To gotowa do produkcji biblioteka agent贸w do budowy aplikacji korporacyjnych. Skupia si na aplikacjach agentowych opartych na zdarzeniach, rozproszonych, umo偶liwiajc wykorzystanie wielu LLM-贸w i SLM-贸w, narzdzi oraz wzorc贸w projektowych dla pojedynczych i wieloagentowych system贸w.
- **Azure AI Agent Service**: To platforma i usuga wdra偶ania agent贸w w Azure Foundry. Oferuje mo偶liwo czenia si z usugami obsugiwanymi przez Azure, takimi jak Azure OpenAI, Azure AI Search, Bing Search i wykonywanie kodu.

Nie jeste pewien, kt贸ry wybra?

### Zastosowania

Spr贸bujmy pom贸c, przechodzc przez kilka typowych scenariuszy:

> P: Eksperymentuj, ucz si i buduj aplikacje agentowe jako proof-of-concept, i chc szybko budowa i eksperymentowa.
>
> O: AutoGen bdzie dobrym wyborem w tym scenariuszu, poniewa偶 koncentruje si na aplikacjach agentowych opartych na zdarzeniach i obsuguje zaawansowane wzorce projektowe dla system贸w wieloagentowych.

> P: Dlaczego AutoGen jest lepszym wyborem ni偶 Semantic Kernel i Azure AI Agent Service w tym przypadku?
>
> O: AutoGen zosta specjalnie zaprojektowany do aplikacji agentowych opartych na zdarzeniach, co czyni go dobrze dopasowanym do automatyzacji zada generowania kodu i analizy danych. Zapewnia niezbdne narzdzia i mo偶liwoci do efektywnego budowania zo偶onych system贸w wieloagentowych.

> P: Brzmi, jakby Azure AI Agent Service te偶 si tu sprawdzi, ma narzdzia do generowania kodu i wicej?
>
> O: Tak, Azure AI Agent Service to platforma dla agent贸w z wbudowanymi mo偶liwociami obsugi wielu modeli, Azure AI Search, Bing Search i Azure Functions. Uatwia budowanie agent贸w w Foundry Portal i wdra偶anie ich na du偶 skal.

> P: Nadal jestem zdezorientowany, po prostu podaj mi jedn opcj.
>
> O: wietnym wyborem jest najpierw zbudowanie aplikacji w Semantic Kernel, a nastpnie u偶ycie Azure AI Agent Service do wdro偶enia agenta. Takie podejcie pozwala atwo utrwali agent贸w, jednoczenie wykorzystujc mo偶liwoci budowy system贸w wieloagentowych w Semantic Kernel. Dodatkowo, Semantic Kernel ma konektor w AutoGen, co uatwia korzystanie z obu framework贸w razem.

Podsumujmy kluczowe r贸偶nice w tabeli:

| Framework | Skupienie | Kluczowe pojcia | Zastosowania |
| --- | --- | --- | --- |
| AutoGen | Aplikacje agentowe oparte na zdarzeniach, rozproszone | Agenci, Persony, Funkcje, Dane | Generowanie kodu, zadania analizy danych |
| Semantic Kernel | Rozumienie i generowanie treci podobnych do ludzkich | Agenci, Moduowe komponenty, Wsp贸praca | Rozumienie jzyka naturalnego, generowanie treci |
| Azure AI Agent Service | Elastyczne modele, bezpieczestwo korporacyjne, Generowanie kodu, Wywoywanie narzdzi | Modularno, Wsp贸praca, Orkiestracja proces贸w | Bezpieczne, skalowalne i elastyczne wdra偶anie agent贸w AI |

Jakie s idealne zastosowania dla ka偶dego z tych framework贸w?

## Czy mog bezporednio zintegrowa moje istniejce narzdzia z ekosystemu Azure, czy potrzebuj oddzielnych rozwiza?

Odpowied藕 brzmi: tak, mo偶esz bezporednio zintegrowa swoje istniejce narzdzia z ekosystemu Azure z Azure AI Agent Service, zwaszcza 偶e zostaa ona zaprojektowana do bezproblemowej wsp贸pracy z innymi usugami Azure. Mo偶esz na przykad zintegrowa Bing, Azure AI Search i Azure Functions. Istnieje r贸wnie偶 gboka integracja z Azure AI Foundry.

W przypadku AutoGen i Semantic Kernel r贸wnie偶 mo偶esz integrowa si z usugami Azure, ale mo偶e to wymaga wywoywania usug Azure z poziomu kodu. Innym sposobem integracji jest u偶ycie SDK Azure do interakcji z usugami Azure z poziomu agent贸w. Dodatkowo, jak wspomniano, mo偶esz u偶y Azure AI Agent Service jako orkiestratora dla agent贸w zbudowanych w AutoGen lub Semantic Kernel, co zapewni atwy dostp do ekosystemu Azure.

### Masz wicej pyta dotyczcych framework贸w agent贸w AI?

Docz do [Azure AI Foundry Discord](https://aka.ms/ai-agents/discord), aby spotka si z innymi uczcymi si, uczestniczy w godzinach konsultacji i uzyska odpowiedzi na pytania dotyczce agent贸w AI.

## 殴r贸da

## Poprzednia lekcja

[Wprowadzenie do agent贸w AI i ich zastosowa](../01-intro-to-ai-agents/README.md)

## Nastpna lekcja

[Zrozumienie wzorc贸w projektowych agent贸w](../03-agentic-design-patterns/README.md)

---

**Zastrze偶enie**:  
Ten dokument zosta przetumaczony za pomoc usugi tumaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia偶 dokadamy wszelkich stara, aby tumaczenie byo precyzyjne, prosimy pamita, 偶e automatyczne tumaczenia mog zawiera bdy lub niecisoci. Oryginalny dokument w jego rodzimym jzyku powinien by uznawany za wiarygodne 藕r贸do. W przypadku informacji krytycznych zaleca si skorzystanie z profesjonalnego tumaczenia wykonanego przez czowieka. Nie ponosimy odpowiedzialnoci za jakiekolwiek nieporozumienia lub bdne interpretacje wynikajce z korzystania z tego tumaczenia.