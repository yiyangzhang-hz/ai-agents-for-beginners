<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-23T08:50:41+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "da"
}
-->
# AI-agenter i produktion: Observabilitet og evaluering

N√•r AI-agenter g√•r fra eksperimentelle prototyper til virkelige applikationer, bliver evnen til at forst√• deres adf√¶rd, overv√•ge deres pr√¶station og systematisk evaluere deres output afg√∏rende.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du vide, hvordan du:
- Forst√•r kernekoncepterne inden for agentobservabilitet og evaluering
- Anvender teknikker til at forbedre agenters pr√¶station, omkostninger og effektivitet
- Systematisk evaluerer dine AI-agenter
- Kontrollerer omkostninger ved at implementere AI-agenter i produktion
- Instrumenterer agenter bygget med AutoGen

M√•let er at give dig viden til at omdanne dine "black box"-agenter til gennemsigtige, h√•ndterbare og p√•lidelige systemer.

_**Bem√¶rk:** Det er vigtigt at implementere AI-agenter, der er sikre og p√•lidelige. Se lektionen [Byg p√•lidelige AI-agenter](./06-building-trustworthy-agents/README.md) for mere information._

## Traces og spans

Observabilitetsv√¶rkt√∏jer som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) repr√¶senterer typisk agentk√∏rsler som traces og spans.

- **Trace** repr√¶senterer en komplet agentopgave fra start til slut (f.eks. h√•ndtering af en brugerforesp√∏rgsel).
- **Spans** er individuelle trin inden for en trace (f.eks. kald til en sprogmodel eller hentning af data).

![Trace-tr√¶ i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uden observabilitet kan en AI-agent f√∏les som en "black box" ‚Äì dens interne tilstand og r√¶sonnement er uigennemsigtige, hvilket g√∏r det sv√¶rt at diagnosticere problemer eller optimere pr√¶stationen. Med observabilitet bliver agenter til "glass boxes," der giver den gennemsigtighed, som er afg√∏rende for at opbygge tillid og sikre, at de fungerer som forventet.

## Hvorfor observabilitet er vigtigt i produktionsmilj√∏er

Overgangen af AI-agenter til produktionsmilj√∏er introducerer nye udfordringer og krav. Observabilitet er ikke l√¶ngere en "nice-to-have," men en kritisk funktion:

*   **Fejlfinding og √•rsagsanalyse**: N√•r en agent fejler eller giver et uventet output, giver observabilitetsv√¶rkt√∏jer de n√∏dvendige traces til at finde kilden til fejlen. Dette er is√¶r vigtigt i komplekse agenter, der kan involvere flere LLM-kald, v√¶rkt√∏jsinteraktioner og betinget logik.
*   **H√•ndtering af latenstid og omkostninger**: AI-agenter er ofte afh√¶ngige af LLM'er og andre eksterne API'er, der faktureres pr. token eller pr. kald. Observabilitet g√∏r det muligt at spore disse kald pr√¶cist, hvilket hj√¶lper med at identificere operationer, der er un√∏digt langsomme eller dyre. Dette g√∏r det muligt for teams at optimere prompts, v√¶lge mere effektive modeller eller redesigne workflows for at styre driftsomkostninger og sikre en god brugeroplevelse.
*   **Tillid, sikkerhed og overholdelse**: I mange applikationer er det vigtigt at sikre, at agenter opf√∏rer sig sikkert og etisk. Observabilitet giver en revisionsspor af agentens handlinger og beslutninger. Dette kan bruges til at opdage og afhj√¶lpe problemer som prompt-injektion, generering af skadeligt indhold eller forkert h√•ndtering af personligt identificerbare oplysninger (PII). For eksempel kan du gennemg√• traces for at forst√•, hvorfor en agent gav et bestemt svar eller brugte et specifikt v√¶rkt√∏j.
*   **Kontinuerlige forbedringssl√∏jfer**: Observabilitetsdata er grundlaget for en iterativ udviklingsproces. Ved at overv√•ge, hvordan agenter pr√¶sterer i den virkelige verden, kan teams identificere forbedringsomr√•der, indsamle data til finjustering af modeller og validere effekten af √¶ndringer. Dette skaber en feedbacksl√∏jfe, hvor produktionsindsigter fra online-evaluering informerer offline-eksperimenter og -forbedringer, hvilket f√∏rer til gradvist bedre agentpr√¶station.

## Vigtige metrics at spore

For at overv√•ge og forst√• agentadf√¶rd b√∏r en r√¶kke metrics og signaler spores. Selvom de specifikke metrics kan variere afh√¶ngigt af agentens form√•l, er nogle universelt vigtige.

Her er nogle af de mest almindelige metrics, som observabilitetsv√¶rkt√∏jer overv√•ger:

**Latenstid:** Hvor hurtigt svarer agenten? Lange ventetider p√•virker brugeroplevelsen negativt. Du b√∏r m√•le latenstid for opgaver og individuelle trin ved at spore agentk√∏rsler. For eksempel kan en agent, der bruger 20 sekunder p√• alle modelkald, accelereres ved at bruge en hurtigere model eller ved at k√∏re modelkald parallelt.

**Omkostninger:** Hvad er udgiften pr. agentk√∏rsel? AI-agenter er afh√¶ngige af LLM-kald, der faktureres pr. token, eller eksterne API'er. Hyppig v√¶rkt√∏jsbrug eller flere prompts kan hurtigt √∏ge omkostningerne. For eksempel, hvis en agent kalder en LLM fem gange for en marginal kvalitetsforbedring, skal du vurdere, om omkostningen er berettiget, eller om du kan reducere antallet af kald eller bruge en billigere model. Realtidsoverv√•gning kan ogs√• hj√¶lpe med at identificere uventede stigninger (f.eks. fejl, der for√•rsager overdrevne API-l√∏kker).

**Foresp√∏rgselsfejl:** Hvor mange foresp√∏rgsler fejlede agenten? Dette kan inkludere API-fejl eller mislykkede v√¶rkt√∏jskald. For at g√∏re din agent mere robust mod disse i produktion kan du ops√¶tte fallback-mekanismer eller retries. F.eks. hvis LLM-udbyder A er nede, skifter du til LLM-udbyder B som backup.

**Brugerfeedback:** Implementering af direkte brugerbed√∏mmelser giver v√¶rdifulde indsigter. Dette kan inkludere eksplicitte vurderinger (üëç/üëé, ‚≠ê1-5 stjerner) eller tekstkommentarer. Konsistent negativ feedback b√∏r alarmere dig, da det er et tegn p√•, at agenten ikke fungerer som forventet.

**Implicit brugerfeedback:** Brugeradf√¶rd giver indirekte feedback, selv uden eksplicitte vurderinger. Dette kan inkludere √∏jeblikkelig omformulering af sp√∏rgsm√•l, gentagne foresp√∏rgsler eller klik p√• en "pr√∏v igen"-knap. F.eks. hvis du ser, at brugere gentagne gange stiller det samme sp√∏rgsm√•l, er det et tegn p√•, at agenten ikke fungerer som forventet.

**N√∏jagtighed:** Hvor ofte producerer agenten korrekte eller √∏nskelige output? Definitionen af n√∏jagtighed varierer (f.eks. korrekthed i probleml√∏sning, pr√¶cision i informationshentning, brugertilfredshed). Det f√∏rste skridt er at definere, hvad succes betyder for din agent. Du kan spore n√∏jagtighed via automatiserede tjek, evalueringsscorer eller m√¶rkning af opgavel√∏sning. For eksempel kan du markere traces som "lykkedes" eller "mislykkedes."

**Automatiserede evalueringsmetrics:** Du kan ogs√• ops√¶tte automatiserede evalueringer. For eksempel kan du bruge en LLM til at vurdere agentens output, f.eks. om det er nyttigt, pr√¶cist eller ej. Der findes ogs√• flere open source-biblioteker, der hj√¶lper med at vurdere forskellige aspekter af agenten. F.eks. [RAGAS](https://docs.ragas.io/) til RAG-agenter eller [LLM Guard](https://llm-guard.com/) til at opdage skadeligt sprog eller prompt-injektion.

I praksis giver en kombination af disse metrics den bedste d√¶kning af en AI-agents sundhed. I dette kapitels [eksempelsnotebook](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) viser vi, hvordan disse metrics ser ud i virkelige eksempler, men f√∏rst l√¶rer vi, hvordan en typisk evalueringsworkflow ser ud.

## Instrument√©r din agent

For at indsamle tracing-data skal du instrumentere din kode. M√•let er at instrumentere agentkoden til at udsende traces og metrics, der kan fanges, behandles og visualiseres af en observabilitetsplatform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) er blevet en industristandard for LLM-observabilitet. Det tilbyder et s√¶t API'er, SDK'er og v√¶rkt√∏jer til at generere, indsamle og eksportere telemetridata.

Der findes mange instrumenteringsbiblioteker, der wrapper eksisterende agentrammer og g√∏r det nemt at eksportere OpenTelemetry-spans til et observabilitetsv√¶rkt√∏j. Nedenfor er et eksempel p√• instrumentering af en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Eksempelsnotebooken](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) i dette kapitel vil demonstrere, hvordan du instrumenterer din AutoGen-agent.

**Manuel oprettelse af spans:** Selvom instrumenteringsbiblioteker giver et godt udgangspunkt, er der ofte tilf√¶lde, hvor mere detaljeret eller tilpasset information er n√∏dvendig. Du kan manuelt oprette spans for at tilf√∏je brugerdefineret applikationslogik. Endnu vigtigere er det, at de kan beriges med brugerdefinerede attributter (ogs√• kendt som tags eller metadata). Disse attributter kan inkludere forretningsspecifikke data, mellemregninger eller enhver kontekst, der kan v√¶re nyttig til fejlfinding eller analyse, s√•som `user_id`, `session_id` eller `model_version`.

Eksempel p√• manuel oprettelse af traces og spans med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agent-evaluering

Observabilitet giver os metrics, men evaluering er processen med at analysere disse data (og udf√∏re tests) for at afg√∏re, hvor godt en AI-agent pr√¶sterer, og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrics, hvordan bruger du dem til at vurdere agenten og tr√¶ffe beslutninger?

Regelm√¶ssig evaluering er vigtig, fordi AI-agenter ofte er ikke-deterministiske og kan udvikle sig (gennem opdateringer eller √¶ndringer i modeladf√¶rd) ‚Äì uden evaluering ville du ikke vide, om din "smarte agent" faktisk g√∏r sit job godt, eller om den er blevet d√•rligere.

Der er to kategorier af evalueringer for AI-agenter: **offline-evaluering** og **online-evaluering**. Begge er v√¶rdifulde og supplerer hinanden. Vi starter normalt med offline-evaluering, da dette er det minimum n√∏dvendige skridt, f√∏r en agent implementeres.

### Offline-evaluering

![Datas√¶t-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette indeb√¶rer at evaluere agenten i et kontrolleret milj√∏, typisk ved hj√¶lp af testdatas√¶t, ikke live brugerforesp√∏rgsler. Du bruger kuraterede datas√¶t, hvor du kender det forventede output eller den korrekte adf√¶rd, og derefter k√∏rer du din agent p√• disse.

For eksempel, hvis du har bygget en agent til matematiske tekstopgaver, kan du have et [testdatas√¶t](https://huggingface.co/datasets/gsm8k) med 100 opgaver med kendte svar. Offline-evaluering udf√∏res ofte under udvikling (og kan v√¶re en del af CI/CD-pipelines) for at kontrollere forbedringer eller beskytte mod regressioner. Fordelen er, at det er **gentageligt, og du kan f√• klare n√∏jagtighedsmetrics, da du har sandhedsv√¶rdier**. Du kan ogs√• simulere brugerforesp√∏rgsler og m√•le agentens svar mod ideelle svar eller bruge automatiserede metrics som beskrevet ovenfor.

Den st√∏rste udfordring ved offline-evaluering er at sikre, at dit testdatas√¶t er omfattende og forbliver relevant ‚Äì agenten kan pr√¶stere godt p√• et fast testdatas√¶t, men st√∏de p√• meget forskellige foresp√∏rgsler i produktion. Derfor b√∏r du holde testdatas√¶t opdateret med nye edge cases og eksempler, der afspejler virkelige scenarier. En blanding af sm√• "smoke test"-cases og st√∏rre evalueringss√¶t er nyttig: sm√• s√¶t til hurtige tjek og st√∏rre s√¶t til bredere pr√¶stationsmetrics.

### Online-evaluering

![Oversigt over observabilitetsmetrics](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til at evaluere agenten i et live, virkeligt milj√∏, dvs. under faktisk brug i produktion. Online-evaluering indeb√¶rer at overv√•ge agentens pr√¶station p√• reelle brugerinteraktioner og analysere resultater l√∏bende.

For eksempel kan du spore succesrater, brugertilfredshedsscorer eller andre metrics p√• live trafik. Fordelen ved online-evaluering er, at den **fanger ting, du m√•ske ikke forudser i et laboratoriemilj√∏** ‚Äì du kan observere modeldrift over tid (hvis agentens effektivitet forringes, n√•r inputm√∏nstre √¶ndrer sig) og opdage uventede foresp√∏rgsler eller situationer, der ikke var i dine testdata. Den giver et sandt billede af, hvordan agenten opf√∏rer sig i praksis.

Online-evaluering involverer ofte indsamling af implicit og eksplicit brugerfeedback, som tidligere n√¶vnt, og muligvis k√∏rsel af shadow tests eller A/B-tests (hvor en ny version af agenten k√∏rer parallelt for at sammenligne med den gamle). Udfordringen er, at det kan v√¶re vanskeligt at f√• p√•lidelige labels eller scorer for live-interaktioner ‚Äì du kan v√¶re afh√¶ngig af brugerfeedback eller downstream-metrics (f.eks. om brugeren klikkede p√• resultatet).

### Kombination af de to

Online- og offline-evalueringer udelukker ikke hinanden; de supplerer hinanden. Indsigter fra online-overv√•gning (f.eks. nye typer brugerforesp√∏rgsler, hvor agenten pr√¶sterer d√•rligt) kan bruges til at udvide og forbedre offline-testdatas√¶t. Omvendt kan agenter, der pr√¶sterer godt i offline-tests, derefter implementeres og overv√•ges online med st√∏rre selvtillid.

Faktisk adopterer mange teams en sl√∏jfe:

_evalu√©r offline -> implement√©r -> overv√•g online -> indsamle nye fejltilf√¶lde -> tilf√∏j til offline-datas√¶t -> forfin agent -> gentag_.

## Almindelige problemer

N√•r du implementerer AI-agenter i produktion, kan du st√∏de p√• forskellige udfordringer. Her er nogle almindelige problemer og deres potentielle l√∏sninger:

| **Problem**    | **Potentiel l√∏sning**   |
| ------------- | ------------------ |
| AI-agent udf√∏rer ikke opgaver konsekvent | - Forfin prompten, der gives til AI-agenten; v√¶r tydelig omkring m√•lene.<br>- Identific√©r, hvor opdeling af opgaver i delopgaver og h√•ndtering af dem af flere agenter kan hj√¶lpe. |
| AI-agent k√∏rer i kontinuerlige l√∏kker  | - S√∏rg for, at der er klare afslutningsbetingelser, s√• agenten ved, hvorn√•r processen skal stoppe.<br>- For komplekse opgaver, der kr√¶ver r√¶sonnement og planl√¶gning, brug en st√∏rre model, der er specialiseret i r√¶sonnement. |
| AI-agentens v√¶rkt√∏jskald fungerer ikke godt   | - Test og valider v√¶rkt√∏jets output uden for agentsystemet. |

- Forfin parametrene, promptene og navngivningen af v√¶rkt√∏jer.  |
| Multi-agent system fungerer ikke konsekvent | - Forfin de prompts, der gives til hver agent, for at sikre, at de er specifikke og adskiller sig fra hinanden.<br>- Opbyg et hierarkisk system ved hj√¶lp af en "routing" eller controller-agent til at afg√∏re, hvilken agent der er den rette. |

Mange af disse problemer kan identificeres mere effektivt, hvis der er observabilitet p√• plads. De spor og metrikker, vi diskuterede tidligere, hj√¶lper med at lokalisere pr√¶cis, hvor i agentens arbejdsproces problemer opst√•r, hvilket g√∏r fejlfinding og optimering langt mere effektiv.

## H√•ndtering af omkostninger

Her er nogle strategier til at h√•ndtere omkostningerne ved at implementere AI-agenter i produktion:

**Brug af mindre modeller:** Sm√• sprogmodeller (SLMs) kan klare sig godt i visse agentbaserede anvendelser og vil reducere omkostningerne betydeligt. Som n√¶vnt tidligere er det bedste m√•de at forst√•, hvor godt en SLM vil klare sig i din anvendelse, at opbygge et evalueringssystem til at bestemme og sammenligne ydeevnen med st√∏rre modeller. Overvej at bruge SLMs til enklere opgaver som hensigtsklassificering eller parameterudtr√¶kning, mens st√∏rre modeller reserveres til kompleks r√¶sonnement.

**Brug af en routermodel:** En lignende strategi er at bruge en diversitet af modeller og st√∏rrelser. Du kan bruge en LLM/SLM eller serverless funktion til at dirigere foresp√∏rgsler baseret p√• kompleksitet til de bedst egnede modeller. Dette vil ogs√• hj√¶lpe med at reducere omkostningerne, samtidig med at ydeevnen p√• de rette opgaver sikres. For eksempel kan simple foresp√∏rgsler dirigeres til mindre, hurtigere modeller, og kun dyre store modeller bruges til komplekse r√¶sonnementopgaver.

**Caching af svar:** Identificering af almindelige foresp√∏rgsler og opgaver og levering af svarene, f√∏r de g√•r gennem dit agentbaserede system, er en god m√•de at reducere volumen af lignende foresp√∏rgsler. Du kan endda implementere en proces til at identificere, hvor lignende en foresp√∏rgsel er med dine cachede foresp√∏rgsler ved hj√¶lp af mere basale AI-modeller. Denne strategi kan betydeligt reducere omkostningerne for ofte stillede sp√∏rgsm√•l eller almindelige arbejdsgange.

## Lad os se, hvordan dette fungerer i praksis

I [eksempelsnotebogen for denne sektion](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√•, hvordan vi kan bruge observabilitetsv√¶rkt√∏jer til at overv√•ge og evaluere vores agent.

## Forrige lektion

[Metakognition Designm√∏nster](../09-metacognition/README.md)

## N√¶ste lektion

[MCP](../11-mcp/README.md)

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at sikre n√∏jagtighed, skal det bem√¶rkes, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os ikke ansvar for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.