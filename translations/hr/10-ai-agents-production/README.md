<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-08-29T23:00:44+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "hr"
}
-->
# AI agenti u produkciji: Promatranje i evaluacija

[![AI agenti u produkciji](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.hr.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Kako AI agenti prelaze iz eksperimentalnih prototipova u stvarne aplikacije, sposobnost razumijevanja njihovog ponaÅ¡anja, praÄ‡enja performansi i sustavne evaluacije njihovih rezultata postaje kljuÄna.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, znat Ä‡ete kako/razumjeti:
- Osnovne koncepte promatranja i evaluacije agenata
- Tehnike za poboljÅ¡anje performansi, troÅ¡kova i uÄinkovitosti agenata
- Å to i kako sustavno evaluirati kod svojih AI agenata
- Kako kontrolirati troÅ¡kove prilikom implementacije AI agenata u produkciju
- Kako instrumentirati agente izgraÄ‘ene s AutoGen-om

Cilj je opremiti vas znanjem kako biste svoje "crne kutije" agente transformirali u transparentne, upravljive i pouzdane sustave.

_**Napomena:** VaÅ¾no je implementirati AI agente koji su sigurni i pouzdani. Pogledajte lekciju [Izgradnja pouzdanih AI agenata](./06-building-trustworthy-agents/README.md) za viÅ¡e informacija._

## Tragovi i segmenti

Alati za promatranje poput [Langfuse](https://langfuse.com/) ili [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) obiÄno prikazuju rad agenata kao tragove i segmente.

- **Trag** predstavlja cjelokupni zadatak agenta od poÄetka do kraja (npr. obrada korisniÄkog upita).
- **Segmenti** su pojedinaÄni koraci unutar traga (npr. pozivanje jeziÄnog modela ili dohvaÄ‡anje podataka).

![Stablo traga u Langfuse-u](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Bez promatranja, AI agent moÅ¾e djelovati kao "crna kutija" - njegovo unutarnje stanje i razmiÅ¡ljanje su nejasni, Å¡to oteÅ¾ava dijagnosticiranje problema ili optimizaciju performansi. S promatranjem, agenti postaju "staklene kutije", pruÅ¾ajuÄ‡i transparentnost koja je kljuÄna za izgradnju povjerenja i osiguranje da rade kako je predviÄ‘eno.

## ZaÅ¡to je promatranje vaÅ¾no u produkcijskim okruÅ¾enjima

Prijelaz AI agenata u produkcijska okruÅ¾enja donosi nove izazove i zahtjeve. Promatranje viÅ¡e nije "lijep dodatak", veÄ‡ kljuÄna sposobnost:

*   **Otklanjanje greÅ¡aka i analiza uzroka problema**: Kada agent zakaÅ¾e ili proizvede neoÄekivani rezultat, alati za promatranje pruÅ¾aju tragove potrebne za pronalaÅ¾enje izvora greÅ¡ke. Ovo je posebno vaÅ¾no kod sloÅ¾enih agenata koji mogu ukljuÄivati viÅ¡e poziva LLM-a, interakcije s alatima i uvjetnu logiku.
*   **Upravljanje latencijom i troÅ¡kovima**: AI agenti Äesto se oslanjaju na LLM-ove i druge vanjske API-je koji se naplaÄ‡uju po tokenu ili pozivu. Promatranje omoguÄ‡uje precizno praÄ‡enje tih poziva, pomaÅ¾uÄ‡i u identificiranju operacija koje su previÅ¡e spore ili skupe. To omoguÄ‡uje timovima optimizaciju upita, odabir uÄinkovitijih modela ili redizajn radnih tokova kako bi upravljali operativnim troÅ¡kovima i osigurali dobro korisniÄko iskustvo.
*   **Povjerenje, sigurnost i usklaÄ‘enost**: U mnogim aplikacijama vaÅ¾no je osigurati da agenti djeluju sigurno i etiÄno. Promatranje pruÅ¾a revizijski trag radnji i odluka agenta. Ovo se moÅ¾e koristiti za otkrivanje i ublaÅ¾avanje problema poput ubrizgavanja upita, generiranja Å¡tetnog sadrÅ¾aja ili nepravilnog rukovanja osobnim podacima (PII). Na primjer, moÅ¾ete pregledati tragove kako biste razumjeli zaÅ¡to je agent dao odreÄ‘eni odgovor ili koristio odreÄ‘eni alat.
*   **Kontinuirani ciklusi poboljÅ¡anja**: Podaci o promatranju temelj su iterativnog procesa razvoja. PraÄ‡enjem kako agenti rade u stvarnom svijetu, timovi mogu identificirati podruÄja za poboljÅ¡anje, prikupiti podatke za fino podeÅ¡avanje modela i potvrditi uÄinak promjena. Ovo stvara povratnu petlju u kojoj produkcijski uvidi iz online evaluacije informiraju offline eksperimentiranje i usavrÅ¡avanje, Å¡to dovodi do progresivno boljih performansi agenata.

## KljuÄne metrike za praÄ‡enje

Za praÄ‡enje i razumijevanje ponaÅ¡anja agenata, potrebno je pratiti niz metrika i signala. Iako se specifiÄne metrike mogu razlikovati ovisno o svrsi agenta, neke su univerzalno vaÅ¾ne.

Evo nekih od najÄeÅ¡Ä‡ih metrika koje alati za promatranje prate:

**Latencija:** Koliko brzo agent odgovara? Dugo Äekanje negativno utjeÄe na korisniÄko iskustvo. Trebali biste mjeriti latenciju za zadatke i pojedinaÄne korake praÄ‡enjem rada agenta. Na primjer, agent koji za sve pozive modela treba 20 sekundi mogao bi se ubrzati koriÅ¡tenjem brÅ¾eg modela ili paralelnim pokretanjem poziva modela.

**TroÅ¡kovi:** Koliki je troÅ¡ak po radu agenta? AI agenti se oslanjaju na LLM pozive koji se naplaÄ‡uju po tokenu ili vanjske API-je. ÄŒesta upotreba alata ili viÅ¡e upita moÅ¾e brzo poveÄ‡ati troÅ¡kove. Na primjer, ako agent poziva LLM pet puta za marginalno poboljÅ¡anje kvalitete, morate procijeniti je li troÅ¡ak opravdan ili moÅ¾ete smanjiti broj poziva ili koristiti jeftiniji model. PraÄ‡enje u stvarnom vremenu takoÄ‘er moÅ¾e pomoÄ‡i u identificiranju neoÄekivanih skokova (npr. greÅ¡ke koje uzrokuju prekomjerne API petlje).

**GreÅ¡ke u zahtjevima:** Koliko zahtjeva je agentu neuspjelo? Ovo moÅ¾e ukljuÄivati API greÅ¡ke ili neuspjele pozive alata. Kako biste uÄinili agenta robusnijim u produkciji, moÅ¾ete postaviti rezervne opcije ili ponovne pokuÅ¡aje. Npr. ako je LLM pruÅ¾atelj A nedostupan, prebacujete se na LLM pruÅ¾atelja B kao rezervu.

**Povratne informacije korisnika:** Implementacija izravnih evaluacija korisnika pruÅ¾a vrijedne uvide. Ovo moÅ¾e ukljuÄivati eksplicitne ocjene (ğŸ‘palac gore/ğŸ‘dolje, â­1-5 zvjezdica) ili tekstualne komentare. Dosljedno negativne povratne informacije trebale bi vas upozoriti jer to ukazuje na to da agent ne radi kako se oÄekuje.

**Implicitne povratne informacije korisnika:** PonaÅ¡anja korisnika pruÅ¾aju neizravne povratne informacije Äak i bez eksplicitnih ocjena. Ovo moÅ¾e ukljuÄivati trenutnu preformulaciju pitanja, ponovljene upite ili klik na gumb za ponovni pokuÅ¡aj. Npr. ako vidite da korisnici opetovano postavljaju isto pitanje, to je znak da agent ne radi kako se oÄekuje.

**ToÄnost:** Koliko Äesto agent proizvodi toÄne ili poÅ¾eljne rezultate? Definicije toÄnosti variraju (npr. toÄnost rjeÅ¡avanja problema, toÄnost dohvaÄ‡anja informacija, zadovoljstvo korisnika). Prvi korak je definirati Å¡to uspjeh znaÄi za vaÅ¡eg agenta. ToÄnost moÅ¾ete pratiti putem automatiziranih provjera, evaluacijskih ocjena ili oznaka zavrÅ¡etka zadatka. Na primjer, oznaÄavanje tragova kao "uspjeÅ¡no" ili "neuspjeÅ¡no".

**Automatizirane evaluacijske metrike:** TakoÄ‘er moÅ¾ete postaviti automatizirane evaluacije. Na primjer, moÅ¾ete koristiti LLM za ocjenjivanje rezultata agenta, npr. je li koristan, toÄan ili nije. Postoji i nekoliko open source biblioteka koje pomaÅ¾u u ocjenjivanju razliÄitih aspekata agenta. Npr. [RAGAS](https://docs.ragas.io/) za RAG agente ili [LLM Guard](https://llm-guard.com/) za otkrivanje Å¡tetnog jezika ili ubrizgavanja upita.

U praksi, kombinacija ovih metrika daje najbolji pregled zdravlja AI agenta. U [primjeru biljeÅ¾nice](./code_samples/10_autogen_evaluation.ipynb) ovog poglavlja pokazat Ä‡emo kako ove metrike izgledaju u stvarnim primjerima, ali prvo Ä‡emo nauÄiti kako izgleda tipiÄan evaluacijski tijek rada.

## Instrumentiranje vaÅ¡eg agenta

Kako biste prikupili podatke o tragovima, trebate instrumentirati svoj kod. Cilj je instrumentirati kod agenta kako bi emitirao tragove i metrike koje se mogu prikupiti, obraditi i vizualizirati pomoÄ‡u platforme za promatranje.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) se pojavio kao industrijski standard za promatranje LLM-a. PruÅ¾a skup API-ja, SDK-ova i alata za generiranje, prikupljanje i izvoz telemetrijskih podataka.

Postoje mnoge biblioteke za instrumentiranje koje obavijaju postojeÄ‡e okvire agenata i olakÅ¡avaju izvoz OpenTelemetry segmenata u alat za promatranje. Ispod je primjer instrumentiranja AutoGen agenta pomoÄ‡u biblioteke [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Primjer biljeÅ¾nice](./code_samples/10_autogen_evaluation.ipynb) u ovom poglavlju pokazat Ä‡e kako instrumentirati vaÅ¡ AutoGen agent.

**RuÄno stvaranje segmenata:** Iako biblioteke za instrumentiranje pruÅ¾aju dobru osnovu, Äesto postoje sluÄajevi kada je potrebno viÅ¡e detaljnih ili prilagoÄ‘enih informacija. MoÅ¾ete ruÄno stvoriti segmente kako biste dodali prilagoÄ‘enu logiku aplikacije. JoÅ¡ vaÅ¾nije, moÅ¾ete obogatiti automatski ili ruÄno stvorene segmente prilagoÄ‘enim atributima (poznatim i kao oznake ili metapodaci). Ti atributi mogu ukljuÄivati poslovno specifiÄne podatke, meÄ‘ukalkulacije ili bilo koji kontekst koji bi mogao biti koristan za otklanjanje greÅ¡aka ili analizu, poput `user_id`, `session_id` ili `model_version`.

Primjer stvaranja tragova i segmenata ruÄno pomoÄ‡u [Langfuse Python SDK-a](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluacija agenata

Promatranje nam daje metrike, ali evaluacija je proces analize tih podataka (i provoÄ‘enja testova) kako bi se utvrdilo koliko dobro AI agent radi i kako se moÅ¾e poboljÅ¡ati. Drugim rijeÄima, jednom kada imate te tragove i metrike, kako ih koristiti za procjenu agenta i donoÅ¡enje odluka?

Redovita evaluacija je vaÅ¾na jer su AI agenti Äesto nedeterministiÄki i mogu se mijenjati (kroz aÅ¾uriranja ili promjene ponaÅ¡anja modela) â€“ bez evaluacije, ne biste znali radi li vaÅ¡ "pametni agent" zapravo dobro ili je nazadovao.

Postoje dvije kategorije evaluacija za AI agente: **online evaluacija** i **offline evaluacija**. Obje su vrijedne i meÄ‘usobno se nadopunjuju. ObiÄno poÄinjemo s offline evaluacijom, jer je to minimalni nuÅ¾ni korak prije implementacije bilo kojeg agenta.

### Offline evaluacija

![Stavke skupa podataka u Langfuse-u](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Ovo ukljuÄuje evaluaciju agenta u kontroliranom okruÅ¾enju, obiÄno koristeÄ‡i testne skupove podataka, a ne upite stvarnih korisnika. Koristite kurirane skupove podataka gdje znate Å¡to je oÄekivani rezultat ili ispravno ponaÅ¡anje, a zatim pokreÄ‡ete svog agenta na njima.

Na primjer, ako ste izgradili agenta za matematiÄke zadatke, mogli biste imati [testni skup podataka](https://huggingface.co/datasets/gsm8k) od 100 problema s poznatim odgovorima. Offline evaluacija Äesto se provodi tijekom razvoja (i moÅ¾e biti dio CI/CD procesa) kako bi se provjerila poboljÅ¡anja ili sprijeÄile regresije. Prednost je Å¡to je **ponovljiva i moÅ¾ete dobiti jasne metrike toÄnosti jer imate poznatu istinu**. TakoÄ‘er moÅ¾ete simulirati korisniÄke upite i mjeriti odgovore agenta u odnosu na idealne odgovore ili koristiti automatizirane metrike kao Å¡to je gore opisano.

KljuÄni izazov kod offline evaluacije je osigurati da vaÅ¡ testni skup podataka bude sveobuhvatan i ostane relevantan â€“ agent moÅ¾e dobro raditi na fiksnom testnom skupu, ali naiÄ‡i na vrlo razliÄite upite u produkciji. Stoga biste trebali aÅ¾urirati testne skupove s novim rubnim sluÄajevima i primjerima koji odraÅ¾avaju stvarne scenarijeâ€‹. Korisna je kombinacija malih "testova dima" i veÄ‡ih evaluacijskih skupova: mali skupovi za brze provjere i veÄ‡i za Å¡ire metrike performansiâ€‹.

### Online evaluacija

![Pregled metrika promatranja](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Ovo se odnosi na evaluaciju agenta u stvarnom, stvarnom okruÅ¾enju, tj. tijekom stvarne upotrebe u produkciji. Online evaluacija ukljuÄuje praÄ‡enje performansi agenta na stvarnim korisniÄkim interakcijama i kontinuiranu analizu rezultata.

Na primjer, mogli biste pratiti stope uspjeha, ocjene zadovoljstva korisnika ili druge metrike na stvarnom prometu. Prednost online evaluacije je Å¡to **biljeÅ¾i stvari koje moÅ¾da ne biste predvidjeli u laboratorijskom okruÅ¾enju** â€“ moÅ¾ete promatrati promjene modela tijekom vremena (ako se uÄinkovitost agenta pogorÅ¡ava kako se obrasci unosa mijenjaju) i uhvatiti neoÄekivane upite ili situacije koje nisu bile u vaÅ¡im testnim podacimaâ€‹. PruÅ¾a pravu sliku o tome kako se agent ponaÅ¡a u stvarnom svijetu.

Online evaluacija Äesto ukljuÄuje prikupljanje implicitnih i eksplicitnih povratnih informacija korisnika, kao Å¡to je gore opisano, i moguÄ‡e provoÄ‘enje testova u sjeni ili A/B testova (gdje nova verzija agenta radi paralelno kako bi se usporedila sa starom). Izazov je Å¡to moÅ¾e biti teÅ¡ko dobiti pouzdane oznake ili ocjene za interakcije uÅ¾ivo â€“ moÅ¾da Ä‡ete se osloniti na povratne informacije korisnika ili metrike nizvodno (npr. je li korisnik kliknuo rezultat).

### Kombiniranje dvaju pristupa

Online i offline evaluacije nisu meÄ‘usobno iskljuÄive; one se snaÅ¾no nadopunjuju. Uvidi iz online praÄ‡enja (npr. nove vrste korisniÄkih upita gdje agent loÅ¡e radi) mogu se koristiti za proÅ¡irenje i poboljÅ¡anje offline testnih skupova podataka. S druge strane, agenti koji dobro rade u offline testovima mogu se s viÅ¡e povjerenja implementirati i pratiti online.

Zapravo, mnogi timovi usvajaju petlju:

_evaluacija offline -> implementacija -> praÄ‡enje online -> prikupljanje novih sluÄajeva neuspjeha -> dodavanje u offline skup podataka -> usavrÅ¡avanje agenta -> ponavljanje_.

## UobiÄajeni problemi

Kada implementirate AI agente u produkciju, moÅ¾ete naiÄ‡i na razne izazove. Evo nekih uobiÄajenih problema i njihovih moguÄ‡ih rjeÅ¡enja:

| **Problem**    | **MoguÄ‡e rjeÅ¡enje**   |
| ------------- | ------------------ |
| AI agent ne obavlja zadatke dosljedno | - PoboljÅ¡ajte upit koji se daje AI agentu; budite jasni u ciljevima.<br>- Identificirajte gdje podjela zadataka na podzadatke i njihovo rukovanje od strane viÅ¡e agenata moÅ¾e pomoÄ‡i. |
| AI agent ulazi u kontinuirane petlje  | - Osigurajte da imate jasne uvjete za prekid kako bi agent znao kada zaustaviti proces. |

- Za sloÅ¾ene zadatke koji zahtijevaju razmiÅ¡ljanje i planiranje, koristite veÄ‡i model specijaliziran za zadatke zakljuÄivanja. |
| AI Agent alati ne daju dobre rezultate   | - Testirajte i provjerite izlaz alata izvan sustava agenta.<br>- PoboljÅ¡ajte definirane parametre, upite i nazive alata.  |
| ViÅ¡eagentski sustav ne radi dosljedno | - PoboljÅ¡ajte upite za svakog agenta kako bi bili specifiÄni i razliÄiti jedni od drugih.<br>- Izgradite hijerarhijski sustav koristeÄ‡i "usmjerivaÄa" ili kontrolnog agenta za odreÄ‘ivanje koji je agent ispravan. |

Mnogi od ovih problema mogu se uÄinkovitije identificirati uz postavljenu moguÄ‡nost praÄ‡enja. Tragovi i metrike koje smo ranije spomenuli pomaÅ¾u precizno odrediti gdje u tijeku rada agenta dolazi do problema, ÄineÄ‡i otklanjanje greÅ¡aka i optimizaciju mnogo uÄinkovitijima.

## Upravljanje troÅ¡kovima

Evo nekoliko strategija za upravljanje troÅ¡kovima implementacije AI agenata u produkciji:

**KoriÅ¡tenje manjih modela:** Mali jeziÄni modeli (SLM) mogu dobro obavljati odreÄ‘ene zadatke u agentiÄkim sluÄajevima upotrebe i znaÄajno smanjiti troÅ¡kove. Kao Å¡to je ranije spomenuto, izgradnja sustava za evaluaciju kako bi se odredila i usporedila izvedba u odnosu na veÄ‡e modele najbolji je naÄin za razumijevanje kako Ä‡e SLM raditi za vaÅ¡ sluÄaj upotrebe. Razmotrite koriÅ¡tenje SLM-ova za jednostavnije zadatke poput klasifikacije namjere ili ekstrakcije parametara, dok veÄ‡e modele rezervirate za sloÅ¾enije zadatke zakljuÄivanja.

**KoriÅ¡tenje modela usmjerivaÄa:** SliÄna strategija je koriÅ¡tenje raznolikosti modela i veliÄina. MoÅ¾ete koristiti LLM/SLM ili serverless funkciju za usmjeravanje zahtjeva na temelju sloÅ¾enosti prema modelima koji najbolje odgovaraju. Ovo Ä‡e takoÄ‘er pomoÄ‡i u smanjenju troÅ¡kova, a istovremeno osigurati izvedbu za odgovarajuÄ‡e zadatke. Na primjer, usmjerite jednostavne upite prema manjim, brÅ¾im modelima, a skupe velike modele koristite samo za sloÅ¾ene zadatke zakljuÄivanja.

**KeÅ¡iranje odgovora:** Identificiranje uobiÄajenih zahtjeva i zadataka te pruÅ¾anje odgovora prije nego Å¡to proÄ‘u kroz vaÅ¡ agentiÄki sustav dobar je naÄin za smanjenje volumena sliÄnih zahtjeva. ÄŒak moÅ¾ete implementirati tijek rada za odreÄ‘ivanje koliko je zahtjev sliÄan vaÅ¡im keÅ¡iranim zahtjevima koristeÄ‡i osnovnije AI modele. Ova strategija moÅ¾e znaÄajno smanjiti troÅ¡kove za Äesto postavljana pitanja ili uobiÄajene tijekove rada.

## Pogledajmo kako ovo funkcionira u praksi

U [primjeru biljeÅ¾nice ovog odjeljka](./code_samples/10_autogen_evaluation.ipynb), vidjet Ä‡emo primjere kako moÅ¾emo koristiti alate za praÄ‡enje i evaluaciju naÅ¡ih agenata.

### Imate joÅ¡ pitanja o AI agentima u produkciji?

PridruÅ¾ite se [Azure AI Foundry Discordu](https://aka.ms/ai-agents/discord) kako biste se povezali s drugim uÄenicima, sudjelovali u uredskim satima i dobili odgovore na svoja pitanja o AI agentima.

## Prethodna lekcija

[Metakognitivni dizajnerski obrazac](../09-metacognition/README.md)

## SljedeÄ‡a lekcija

[AgentiÄki protokoli](../11-agentic-protocols/README.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koriÅ¡tenjem AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati mjerodavnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane struÄnjaka. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogreÅ¡ne interpretacije proizaÅ¡le iz koriÅ¡tenja ovog prijevoda.