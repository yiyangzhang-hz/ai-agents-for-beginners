<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-23T09:17:35+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "hr"
}
-->
# AI Agenti u Produkciji: Promatranje i Evaluacija

Kako AI agenti prelaze iz eksperimentalnih prototipova u stvarne aplikacije, sposobnost razumijevanja njihovog ponaÅ¡anja, praÄ‡enja performansi i sustavne evaluacije njihovih rezultata postaje kljuÄna.

## Ciljevi UÄenja

Nakon zavrÅ¡etka ove lekcije, znat Ä‡ete kako/razumjeti:
- Osnovne koncepte promatranja i evaluacije agenata
- Tehnike za poboljÅ¡anje performansi, troÅ¡kova i uÄinkovitosti agenata
- Å to i kako sustavno evaluirati kod vaÅ¡ih AI agenata
- Kako kontrolirati troÅ¡kove prilikom implementacije AI agenata u produkciju
- Kako instrumentirati agente izgraÄ‘ene s AutoGen-om

Cilj je opremiti vas znanjem kako biste svoje "crne kutije" agente pretvorili u transparentne, upravljive i pouzdane sustave.

_**Napomena:** VaÅ¾no je implementirati AI agente koji su sigurni i pouzdani. Pogledajte lekciju [Izgradnja Pouzdanih AI Agenata](./06-building-trustworthy-agents/README.md) za viÅ¡e informacija._

## Tragovi i Rasponi

Alati za promatranje poput [Langfuse](https://langfuse.com/) ili [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) obiÄno predstavljaju rad agenata kao tragove i raspon.

- **Trag** predstavlja cijeli zadatak agenta od poÄetka do kraja (npr. obrada korisniÄkog upita).
- **Rasponi** su pojedinaÄni koraci unutar traga (npr. pozivanje jeziÄnog modela ili dohvaÄ‡anje podataka).

![Stablo traga u Langfuse-u](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Bez promatranja, AI agent moÅ¾e djelovati kao "crna kutija" - njegovo unutarnje stanje i razmiÅ¡ljanje su neprozirni, Å¡to oteÅ¾ava dijagnosticiranje problema ili optimizaciju performansi. S promatranjem, agenti postaju "staklene kutije", pruÅ¾ajuÄ‡i transparentnost koja je kljuÄna za izgradnju povjerenja i osiguranje da rade kako je predviÄ‘eno.

## ZaÅ¡to je Promatranje VaÅ¾no u Produkcijskim OkruÅ¾enjima

Prijelaz AI agenata u produkcijska okruÅ¾enja donosi nove izazove i zahtjeve. Promatranje viÅ¡e nije "lijepo imati", veÄ‡ kljuÄna sposobnost:

*   **Otklanjanje greÅ¡aka i analiza uzroka problema**: Kada agent zakaÅ¾e ili proizvede neoÄekivani rezultat, alati za promatranje pruÅ¾aju tragove potrebne za pronalaÅ¾enje izvora greÅ¡ke. Ovo je posebno vaÅ¾no kod sloÅ¾enih agenata koji mogu ukljuÄivati viÅ¡e poziva LLM-a, interakcije s alatima i uvjetnu logiku.
*   **Upravljanje latencijom i troÅ¡kovima**: AI agenti Äesto se oslanjaju na LLM-ove i druge vanjske API-je koji se naplaÄ‡uju po tokenu ili pozivu. Promatranje omoguÄ‡uje precizno praÄ‡enje tih poziva, pomaÅ¾uÄ‡i u identificiranju operacija koje su previÅ¡e spore ili skupe. Ovo omoguÄ‡uje timovima da optimiziraju upite, odaberu uÄinkovitije modele ili redizajniraju tijekove rada kako bi upravljali operativnim troÅ¡kovima i osigurali dobro korisniÄko iskustvo.
*   **Povjerenje, sigurnost i usklaÄ‘enost**: U mnogim aplikacijama vaÅ¾no je osigurati da agenti djeluju sigurno i etiÄno. Promatranje pruÅ¾a revizijski trag radnji i odluka agenta. Ovo se moÅ¾e koristiti za otkrivanje i ublaÅ¾avanje problema poput ubrizgavanja upita, generiranja Å¡tetnog sadrÅ¾aja ili nepravilnog rukovanja osobnim podacima (PII). Na primjer, moÅ¾ete pregledati tragove kako biste razumjeli zaÅ¡to je agent dao odreÄ‘eni odgovor ili koristio odreÄ‘eni alat.
*   **Kontinuirani ciklusi poboljÅ¡anja**: Podaci o promatranju temelj su iterativnog procesa razvoja. PraÄ‡enjem kako agenti rade u stvarnom svijetu, timovi mogu identificirati podruÄja za poboljÅ¡anje, prikupiti podatke za fino podeÅ¡avanje modela i validirati uÄinke promjena. Ovo stvara povratnu petlju u kojoj uvidi iz produkcijske evaluacije informiraju offline eksperimente i dorade, Å¡to dovodi do progresivno boljih performansi agenata.

## KljuÄne Metrike za PraÄ‡enje

Kako biste pratili i razumjeli ponaÅ¡anje agenta, potrebno je pratiti niz metrika i signala. Iako specifiÄne metrike mogu varirati ovisno o svrsi agenta, neke su univerzalno vaÅ¾ne.

Evo nekih od najÄeÅ¡Ä‡ih metrika koje alati za promatranje prate:

**Latencija:** Koliko brzo agent odgovara? Duga Äekanja negativno utjeÄu na korisniÄko iskustvo. Trebali biste mjeriti latenciju za zadatke i pojedinaÄne korake praÄ‡enjem rada agenta. Na primjer, agent koji troÅ¡i 20 sekundi na sve pozive modela mogao bi se ubrzati koriÅ¡tenjem brÅ¾eg modela ili paralelnim izvrÅ¡avanjem poziva modela.

**TroÅ¡kovi:** Koliki je troÅ¡ak po radu agenta? AI agenti oslanjaju se na LLM pozive koji se naplaÄ‡uju po tokenu ili vanjske API-je. ÄŒesta upotreba alata ili viÅ¡estruki upiti mogu brzo poveÄ‡ati troÅ¡kove. Na primjer, ako agent poziva LLM pet puta za marginalno poboljÅ¡anje kvalitete, morate procijeniti je li troÅ¡ak opravdan ili moÅ¾ete smanjiti broj poziva ili koristiti jeftiniji model. PraÄ‡enje u stvarnom vremenu takoÄ‘er moÅ¾e pomoÄ‡i u otkrivanju neoÄekivanih skokova (npr. greÅ¡ke koje uzrokuju prekomjerne API petlje).

**GreÅ¡ke u zahtjevima:** Koliko je zahtjeva agentu neuspjelo? Ovo moÅ¾e ukljuÄivati API greÅ¡ke ili neuspjele pozive alata. Kako biste uÄinili agenta otpornijim na ove greÅ¡ke u produkciji, moÅ¾ete postaviti rezervne opcije ili ponovne pokuÅ¡aje. Npr. ako je LLM pruÅ¾atelj A nedostupan, prebacite se na LLM pruÅ¾atelja B kao rezervu.

**Povratne informacije korisnika:** Implementacija izravnih korisniÄkih evaluacija pruÅ¾a vrijedne uvide. Ovo moÅ¾e ukljuÄivati eksplicitne ocjene (ğŸ‘palac gore/ğŸ‘dolje, â­1-5 zvjezdica) ili tekstualne komentare. Dosljedno negativne povratne informacije trebale bi vas upozoriti jer to ukazuje na to da agent ne radi kako se oÄekuje.

**Implicitne povratne informacije korisnika:** PonaÅ¡anja korisnika pruÅ¾aju neizravne povratne informacije Äak i bez eksplicitnih ocjena. Ovo moÅ¾e ukljuÄivati trenutno preformuliranje pitanja, ponovljene upite ili klikanje na gumb za ponovni pokuÅ¡aj. Npr. ako vidite da korisnici stalno postavljaju isto pitanje, to je znak da agent ne radi kako se oÄekuje.

**ToÄnost:** Koliko Äesto agent proizvodi toÄne ili poÅ¾eljne rezultate? Definicije toÄnosti variraju (npr. toÄnost rjeÅ¡avanja problema, toÄnost dohvaÄ‡anja informacija, zadovoljstvo korisnika). Prvi korak je definirati Å¡to znaÄi uspjeh za vaÅ¡eg agenta. ToÄnost moÅ¾ete pratiti putem automatiziranih provjera, evaluacijskih ocjena ili oznaka dovrÅ¡enih zadataka. Na primjer, oznaÄavanje tragova kao "uspjeÅ¡nih" ili "neuspjeÅ¡nih".

**Automatizirane evaluacijske metrike:** TakoÄ‘er moÅ¾ete postaviti automatizirane evaluacije. Na primjer, moÅ¾ete koristiti LLM za ocjenjivanje rezultata agenta, npr. je li koristan, toÄan ili ne. Postoji i nekoliko open source biblioteka koje vam pomaÅ¾u ocijeniti razliÄite aspekte agenta. Npr. [RAGAS](https://docs.ragas.io/) za RAG agente ili [LLM Guard](https://llm-guard.com/) za otkrivanje Å¡tetnog jezika ili ubrizgavanja upita.

U praksi, kombinacija ovih metrika daje najbolji pregled zdravlja AI agenta. U [primjeru biljeÅ¾nice](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) ovog poglavlja pokazat Ä‡emo kako ove metrike izgledaju u stvarnim primjerima, ali prvo Ä‡emo nauÄiti kako izgleda tipiÄan tijek evaluacije.

## Instrumentiranje VaÅ¡eg Agenta

Kako biste prikupili podatke o praÄ‡enju, trebate instrumentirati svoj kod. Cilj je instrumentirati kod agenta kako bi emitirao tragove i metrike koje se mogu uhvatiti, obraditi i vizualizirati pomoÄ‡u platforme za promatranje.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) se pojavio kao industrijski standard za promatranje LLM-a. PruÅ¾a skup API-ja, SDK-ova i alata za generiranje, prikupljanje i izvoz telemetrijskih podataka.

Postoje mnoge biblioteke za instrumentiranje koje obavijaju postojeÄ‡e okvire za agente i olakÅ¡avaju izvoz OpenTelemetry raspona u alat za promatranje. Ispod je primjer instrumentiranja AutoGen agenta s [OpenLit bibliotekom za instrumentiranje](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Primjer biljeÅ¾nice](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) u ovom poglavlju pokazat Ä‡e kako instrumentirati vaÅ¡ AutoGen agent.

**RuÄno Stvaranje Raspona:** Iako biblioteke za instrumentiranje pruÅ¾aju dobru osnovu, Äesto postoje sluÄajevi gdje su potrebne detaljnije ili prilagoÄ‘ene informacije. MoÅ¾ete ruÄno stvoriti raspone kako biste dodali prilagoÄ‘enu logiku aplikacije. JoÅ¡ vaÅ¾nije, moÅ¾ete obogatiti automatski ili ruÄno stvorene raspone prilagoÄ‘enim atributima (poznatim i kao oznake ili metapodaci). Ovi atributi mogu ukljuÄivati poslovno specifiÄne podatke, meÄ‘urezultate ili bilo koji kontekst koji bi mogao biti koristan za otklanjanje greÅ¡aka ili analizu, poput `user_id`, `session_id` ili `model_version`.

Primjer stvaranja tragova i raspona ruÄno pomoÄ‡u [Langfuse Python SDK-a](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluacija Agenta

Promatranje nam daje metrike, ali evaluacija je proces analize tih podataka (i provoÄ‘enja testova) kako bismo utvrdili koliko dobro AI agent radi i kako ga moÅ¾emo poboljÅ¡ati. Drugim rijeÄima, kada imate te tragove i metrike, kako ih koristiti za procjenu agenta i donoÅ¡enje odluka?

Redovita evaluacija je vaÅ¾na jer su AI agenti Äesto nedeterministiÄki i mogu se mijenjati (kroz aÅ¾uriranja ili promjene u ponaÅ¡anju modela) â€“ bez evaluacije, ne biste znali radi li vaÅ¡ "pametni agent" zapravo dobro ili je nazadovao.

Postoje dvije kategorije evaluacija za AI agente: **offline evaluacija** i **online evaluacija**. Obje su vrijedne i meÄ‘usobno se nadopunjuju. ObiÄno poÄinjemo s offline evaluacijom, jer je to minimalni nuÅ¾ni korak prije implementacije bilo kojeg agenta.

### Offline Evaluacija

![Stavke skupa podataka u Langfuse-u](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Ovo ukljuÄuje evaluaciju agenta u kontroliranom okruÅ¾enju, obiÄno koristeÄ‡i testne skupove podataka, a ne upite uÅ¾ivo korisnika. Koristite kurirane skupove podataka gdje znate koji je oÄekivani rezultat ili ispravno ponaÅ¡anje, a zatim pokreÄ‡ete agenta na njima.

Na primjer, ako ste izgradili agenta za matematiÄke problemske zadatke, mogli biste imati [testni skup podataka](https://huggingface.co/datasets/gsm8k) od 100 problema s poznatim odgovorima. Offline evaluacija se Äesto provodi tijekom razvoja (i moÅ¾e biti dio CI/CD procesa) kako bi se provjerila poboljÅ¡anja ili sprijeÄile regresije. Prednost je Å¡to je **ponovljiva i moÅ¾ete dobiti jasne metrike toÄnosti jer imate poznatu istinu**. TakoÄ‘er moÅ¾ete simulirati korisniÄke upite i mjeriti odgovore agenta u odnosu na idealne odgovore ili koristiti automatizirane metrike kao Å¡to je gore opisano.

KljuÄni izazov kod offline evaluacije je osigurati da vaÅ¡ testni skup podataka bude sveobuhvatan i ostane relevantan â€“ agent moÅ¾e dobro raditi na fiksnom testnom skupu, ali naiÄ‡i na vrlo razliÄite upite u produkciji. Stoga biste trebali aÅ¾urirati testne skupove s novim rubnim sluÄajevima i primjerima koji odraÅ¾avaju stvarne scenarije. Kombinacija malih "dimnih testova" i veÄ‡ih evaluacijskih skupova je korisna: mali skupovi za brze provjere i veÄ‡i za Å¡ire metrike performansi.

### Online Evaluacija

![Pregled metrika promatranja](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Ovo se odnosi na evaluaciju agenta u stvarnom, stvarnom okruÅ¾enju, tj. tijekom stvarne upotrebe u produkciji. Online evaluacija ukljuÄuje kontinuirano praÄ‡enje performansi agenta na stvarnim korisniÄkim interakcijama i analizu rezultata.

Na primjer, mogli biste pratiti stope uspjeha, ocjene zadovoljstva korisnika ili druge metrike na stvarnom prometu. Prednost online evaluacije je Å¡to **obuhvaÄ‡a stvari koje moÅ¾da ne biste predvidjeli u laboratorijskom okruÅ¾enju** â€“ moÅ¾ete promatrati promjene modela tijekom vremena (ako se uÄinkovitost agenta smanjuje kako se obrasci unosa mijenjaju) i uhvatiti neoÄekivane upite ili situacije koje nisu bile u vaÅ¡im testnim podacima. PruÅ¾a pravu sliku o tome kako se agent ponaÅ¡a u stvarnom svijetu.

Online evaluacija Äesto ukljuÄuje prikupljanje implicitnih i eksplicitnih povratnih informacija korisnika, kao Å¡to je ranije spomenuto, i moguÄ‡e provoÄ‘enje shadow testova ili A/B testova (gdje nova verzija agenta radi paralelno za usporedbu s prethodnom). Izazov je Å¡to moÅ¾e biti teÅ¡ko dobiti pouzdane oznake ili ocjene za interakcije uÅ¾ivo â€“ moÅ¾da Ä‡ete se osloniti na povratne informacije korisnika ili dolazne metrike (npr. je li korisnik kliknuo na rezultat).

### Kombiniranje Oba Pristupa

Online i offline evaluacije nisu meÄ‘usobno iskljuÄive; one se snaÅ¾no nadopunjuju. Uvidi iz online praÄ‡enja (npr. novi tipovi korisniÄkih upita gdje agent loÅ¡e radi) mogu se koristiti za proÅ¡irenje i poboljÅ¡anje offline testnih skupova podataka. S druge strane, agenti koji dobro prolaze offline testove mogu se s viÅ¡e povjerenja implementirati i pratiti online.

Zapravo, mnogi timovi usvajaju petlju:

_evaluacija offline -> implementacija -> praÄ‡enje online -> prikupljanje novih sluÄajeva neuspjeha -> dodavanje u offline skup podataka -> dorada agenta -> ponavljanje_.

## UobiÄajeni Problemi

Prilikom implementacije AI agenata u produkciju, moÅ¾ete naiÄ‡i na razne izazove. Evo nekih uobiÄajenih problema i njihovih moguÄ‡ih rjeÅ¡enja:

| **Problem**    | **MoguÄ‡e RjeÅ¡enje**   |
| ------------- | ------------------ |
| AI agent ne obavlja zadatke dosljedno | - Doradite upit koji se daje AI agentu; budite jasni u ciljevima.<br>- Identificirajte gdje podjela zadataka na podzadatke i njihovo rjeÅ¡avanje pomoÄ‡u viÅ¡e agenata moÅ¾e pomoÄ‡i. |
| AI agent ulazi u kontinuirane petlje  | - Osigurajte da imate jasne uvjete za prekid kako bi agent znao kada zaustaviti proces.<br>- Za sloÅ¾ene zadatke koji zahtijevaju razmiÅ¡ljanje i planiranje, koristite veÄ‡i model specijaliziran za zadatke razmiÅ¡ljanja. |
| Pozivi alata AI agenta ne rade dobro   | - Testirajte i validirajte izlaz alata izvan sustava agenta. |

- Precizirajte definirane parametre, upite i nazive alata.  |
| ViÅ¡estruki agentski sustav ne radi dosljedno | - Precizirajte upite za svakog agenta kako bi bili specifiÄni i razliÄiti jedan od drugog.<br>- Izgradite hijerarhijski sustav koristeÄ‡i "usmjerivaÄa" ili kontrolnog agenta kako biste odredili koji je agent ispravan. |

Mnogi od ovih problema mogu se uÄinkovitije identificirati uz postavljenu moguÄ‡nost promatranja. Tragovi i metrike o kojima smo ranije raspravljali pomaÅ¾u toÄno odrediti gdje u tijeku rada agenta dolazi do problema, ÄineÄ‡i otklanjanje pogreÅ¡aka i optimizaciju mnogo uÄinkovitijima.

## Upravljanje troÅ¡kovima

Evo nekoliko strategija za upravljanje troÅ¡kovima prilikom implementacije AI agenata u produkciju:

**KoriÅ¡tenje manjih modela:** Mali jeziÄni modeli (SLM) mogu dobro obavljati odreÄ‘ene zadatke u agentskim sustavima i znaÄajno smanjiti troÅ¡kove. Kao Å¡to je ranije spomenuto, izgradnja sustava za evaluaciju kako bi se odredila i usporedila izvedba u odnosu na veÄ‡e modele najbolji je naÄin za razumijevanje kako Ä‡e SLM raditi na vaÅ¡em sluÄaju upotrebe. Razmotrite koriÅ¡tenje SLM-ova za jednostavnije zadatke poput klasifikacije namjere ili ekstrakcije parametara, dok veÄ‡e modele rezervirate za sloÅ¾enije zadatke zakljuÄivanja.

**KoriÅ¡tenje modela usmjerivaÄa:** SliÄna strategija je koriÅ¡tenje raznolikosti modela i veliÄina. MoÅ¾ete koristiti LLM/SLM ili serverless funkciju za usmjeravanje zahtjeva na modele koji najbolje odgovaraju sloÅ¾enosti zadatka. Ovo Ä‡e takoÄ‘er pomoÄ‡i u smanjenju troÅ¡kova, a istovremeno osigurati izvedbu na pravim zadacima. Na primjer, usmjerite jednostavne upite na manje, brÅ¾e modele, a skupe velike modele koristite samo za sloÅ¾ene zadatke zakljuÄivanja.

**KeÅ¡iranje odgovora:** Identificiranje uobiÄajenih zahtjeva i zadataka te pruÅ¾anje odgovora prije nego Å¡to proÄ‘u kroz vaÅ¡ agentski sustav dobar je naÄin za smanjenje volumena sliÄnih zahtjeva. MoÅ¾ete Äak implementirati tijek rada za identificiranje koliko je zahtjev sliÄan vaÅ¡im keÅ¡iranim zahtjevima koristeÄ‡i osnovnije AI modele. Ova strategija moÅ¾e znaÄajno smanjiti troÅ¡kove za Äesto postavljana pitanja ili uobiÄajene tijekove rada.

## Pogledajmo kako to funkcionira u praksi

U [primjeru biljeÅ¾nice ovog odjeljka](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb), vidjet Ä‡emo primjere kako moÅ¾emo koristiti alate za promatranje za praÄ‡enje i evaluaciju naÅ¡eg agenta.

## Prethodna lekcija

[Metakognitivni dizajnerski obrazac](../09-metacognition/README.md)

## SljedeÄ‡a lekcija

[MCP](../11-mcp/README.md)

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡na tumaÄenja koja mogu proizaÄ‡i iz koriÅ¡tenja ovog prijevoda.